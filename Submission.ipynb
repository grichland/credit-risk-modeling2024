{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":50160,"databundleVersionId":7921029,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport polars as pl\nimport os\n\npd.set_option('display.max_columns', 1000)\npd.set_option('display.max_rows', 1000)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T00:44:28.801684Z","iopub.execute_input":"2024-05-10T00:44:28.802182Z","iopub.status.idle":"2024-05-10T00:44:28.808981Z","shell.execute_reply.started":"2024-05-10T00:44:28.802148Z","shell.execute_reply":"2024-05-10T00:44:28.807417Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"def calculate_woe_iv_categorical(feature, response):\n    # Calculate the total number of events (positive responses) and non-events (negative responses)\n    total_events = response.sum()\n    total_non_events = response.count() - total_events\n    \n    # Create a new DataFrame with the feature and response values\n    df = pd.DataFrame({'bin': feature.fillna('missing'), 'response': response})\n    \n    # Calculate the percentage of events and non-events for each bin of the feature\n    bin_summary = df.groupby('bin')['response'].agg(['sum', 'count']).reset_index()\n    bin_summary.columns = ['bin', 'events', 'total']\n    bin_summary['non-events'] = (bin_summary['total'] - bin_summary['events']) \n    bin_summary['event_rate'] = (bin_summary['events'] / total_events)\n    bin_summary['non-event_rate'] = (bin_summary['non-events'] / total_non_events) + 1e-10 # epsilon so that that the non event rate is not 0\n\n    # Calculate the Weight of Evidence (WOE) and Information Value (IV) for each bin\n    bin_summary['WOE'] = np.log1p(bin_summary['event_rate'] / bin_summary['non-event_rate'])\n    bin_summary['IV'] = (bin_summary['event_rate'] - bin_summary['non-event_rate']) * bin_summary['WOE']\n\n    # # Calculate the total Information Value (IV) for the feature\n    total_IV = bin_summary['IV'].sum()\n    \n    return total_IV\n\ndef calculate_woe_iv_numeric(feature, response,quantiles = 50):\n    # Calculate the total number of events (positive responses) and non-events (negative responses)\n    total_events = response.sum()\n    total_non_events = response.count() - total_events\n    \n    # Create a new DataFrame with the feature and response values\n    df = pd.DataFrame({'feature': feature, 'response': response})\n    \n    # we want to support missing values\n    df['bin'] = -1\n    df.loc[df['feature'].notnull(),'bin'] = pd.qcut(df.loc[df['feature'].notnull(),'feature'], q=quantiles,duplicates='drop',labels=False)\n\n    del df['feature']\n    # Calculate the percentage of events and non-events for each bin of the feature\n    bin_summary = df.groupby('bin')['response'].agg(['sum', 'count']).reset_index()\n    bin_summary.columns = ['bin', 'events', 'total']\n    bin_summary['non-events'] = (bin_summary['total'] - bin_summary['events']) \n    bin_summary['event_rate'] = (bin_summary['events'] / total_events)\n    bin_summary['non-event_rate'] = (bin_summary['non-events'] / total_non_events) + 1e-10 # epsilon so that that the non event rate is not 0\n\n    # Calculate the Weight of Evidence (WOE) and Information Value (IV) for each bin\n    bin_summary['WOE'] = np.log1p(bin_summary['event_rate'] / bin_summary['non-event_rate'])\n    bin_summary['IV'] = (bin_summary['event_rate'] - bin_summary['non-event_rate']) * bin_summary['WOE']\n\n    # # Calculate the total Information Value (IV) for the feature\n    total_IV = bin_summary['IV'].sum()\n    \n    return total_IV\n\ndef calculate_psi_categorical(old,new): \n    # series 1 = old, series 2 = new\n    old = old.fillna(\"missing\")\n    new = new.fillna(\"missing\")    \n    \n    bins = list(set(old.tolist()+new.tolist())) \n    bin_summary = pd.DataFrame(bins,columns=['bin'])\n    bin_summary['prop_old'] = (bin_summary['bin'].apply(lambda x: (old==x).sum()) / len(old)) + 1e-10 # epsilon\n    bin_summary['prop_new'] = (bin_summary['bin'].apply(lambda x: (new==x).sum()) / len(new)) + 1e-10 # epsilon\n\n    \n    return np.sum((bin_summary['prop_old'] - bin_summary['prop_new']) * np.log(bin_summary['prop_old']/bin_summary['prop_new']))\n\ndef calculate_psi_numeric(old,new,q=10): \n\n    old = pd.DataFrame(old,columns=['val'])\n    new = pd.DataFrame(new,columns=['val'])\n    \n    # set up initial bins for missing values\n    old['bin'] = -1\n    new['bin'] = -1\n    \n    \n    # we will only generate a score if we have enough unique values\n    if (old['val'].dropna().nunique() > 1) and (new['val'].dropna().nunique() > 1):\n        # assign each value to a quantile \n        old.loc[old.notnull(),'bin'] = pd.qcut(old.loc[old.notnull(),'val'], q=quantiles,duplicates='drop',labels=False)\n        new.loc[new.notnull(),'bin'] = pd.qcut(new.loc[old.notnull(),'val'], q=quantiles,duplicates='drop',labels=False)\n        \n    \n        bins = list(set(old['bin'].tolist()+new['bin'].tolist())) \n        bin_summary = pd.DataFrame(bins,columns=['bin'])\n        bin_summary['prop_old'] = (bin_summary['bin'].apply(lambda x: (old['bin']==x).sum()) / len(old)) + 1e-10 # epsilon\n        bin_summary['prop_new'] = (bin_summary['bin'].apply(lambda x: (new['bin']==x).sum()) / len(new)) + 1e-10 # epsilon\n    \n        return np.sum((bin_summary['prop_old'] - bin_summary['prop_new']) * np.log(bin_summary['prop_old']/bin_summary['prop_new']))\n    \n    else:\n        return np.nan","metadata":{"execution":{"iopub.status.busy":"2024-05-10T00:44:28.865475Z","iopub.execute_input":"2024-05-10T00:44:28.866020Z","iopub.status.idle":"2024-05-10T00:44:28.889892Z","shell.execute_reply.started":"2024-05-10T00:44:28.865978Z","shell.execute_reply":"2024-05-10T00:44:28.888493Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"markdown","source":"[Data Info](https://www.kaggle.com/competitions/home-credit-credit-risk-model-stability/data) <br>\n[Discussion on how the data is setup](https://www.kaggle.com/competitions/home-credit-credit-risk-model-stability/discussion/473950) <br>\n[Starter Notebook](https://www.kaggle.com/code/jetakow/home-credit-2024-starter-notebook)\n* depth=0 - These are static features directly tied to a specific case_id.\n* depth=1 - Each case_id has an associated historical record, indexed by num_group1.\n* depth=2 - Each case_id has an associated historical record, indexed by both num_group1 and num_group2.","metadata":{}},{"cell_type":"code","source":"class Aggregator:\n    # Please add or subtract features yourself, be aware that too many features will take up too much space.\n    def num_expr(df):\n        cols = [col for col in df.columns if col[-1] in (\"P\", \"A\")]\n        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n        expr_mean = [pl.mean(col).alias(f\"mean_{col}\") for col in cols]\n        expr_median = [pl.median(col).alias(f\"median_{col}\") for col in cols]\n        expr_var = [pl.var(col).alias(f\"var_{col}\") for col in cols]\n\n        return expr_max + expr_last + expr_mean \n\n    def date_expr(df):\n        cols = [col for col in df.columns if col[-1] in (\"D\")]\n        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n        expr_mean = [pl.mean(col).alias(f\"mean_{col}\") for col in cols]\n        expr_median = [pl.median(col).alias(f\"median_{col}\") for col in cols]\n\n        return expr_max + expr_last + expr_mean \n\n    def str_expr(df):\n        cols = [col for col in df.columns if col[-1] in (\"M\",)]\n        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n        # expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n        # expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n        # expr_count = [pl.count(col).alias(f\"count_{col}\") for col in cols]\n        return expr_max + expr_last  # +expr_count\n\n    def other_expr(df):\n        cols = [col for col in df.columns if col[-1] in (\"T\", \"L\")]\n        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n        # expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n        # expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n        return expr_max + expr_last\n\n    def count_expr(df):\n        cols = [col for col in df.columns if \"num_group\" in col]\n        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n        # expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n        # expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n        return expr_max + expr_last\n\n    def get_exprs(df):\n        exprs = Aggregator.num_expr(df) + \\\n                Aggregator.date_expr(df) + \\\n                Aggregator.str_expr(df) + \\\n                Aggregator.other_expr(df) + \\\n                Aggregator.count_expr(df)\n\n        return exprs","metadata":{"execution":{"iopub.status.busy":"2024-05-10T00:44:28.897042Z","iopub.execute_input":"2024-05-10T00:44:28.897534Z","iopub.status.idle":"2024-05-10T00:44:28.913746Z","shell.execute_reply.started":"2024-05-10T00:44:28.897496Z","shell.execute_reply":"2024-05-10T00:44:28.912302Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"class DatasetBuilder:\n    \"\"\" This class is used to create the dataset \"\"\"\n    def __init__(self, \n                 n_samples   = None, \n                 parent_path = \"/kaggle/input/home-credit-credit-risk-model-stability\"):\n        \n\n\n        self.parent_path = parent_path\n        self.n_samples = n_samples\n\n        self.feat_info = pd.read_csv(f\"{parent_path}/feature_definitions.csv\")\n        self.date_cols = []\n        self.string_cols = []\n        self.unspecified_transform_cols = []\n        \n        self.run()\n\n    def explain_feat(self,feat_name:str):\n        assert feat_name in self.feat_info['Variable'].unique(), \"feature not found in feature info dataframe\"\n        return self.feat_info[self.feat_info['Variable']==feat_name]['Description'].values[0]\n\n    def set_table_dtypes(self,df):\n        for col in df.columns:\n            \n            if col in [\"case_id\", \"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n                df = df.with_columns(pl.col(col).cast(pl.Int32))\n            elif col in [\"date_decision\"]:\n                df = df.with_columns(pl.col(col).cast(pl.Date))\n            elif col[-1] in (\"P\", \"A\"):\n                df = df.with_columns(pl.col(col).cast(pl.Float32))\n            elif col[-1] in (\"M\",):\n                df = df.with_columns(pl.col(col).cast(pl.String))\n                if col not in self.string_cols:\n                    self.string_cols.append(col)\n            elif col[-1] in (\"L\",\"T\"): # we dont know the transform needed, just going to assume its either float and if not, then string\n                try:\n                    df = df.with_columns(pl.col(col).cast(pl.Float32))\n                except:\n                    df = df.with_columns(pl.col(col).cast(pl.String))\n                    if col not in self.string_cols:\n                        self.string_cols.append(col) \n                    continue\n                \n            elif col[-1] in (\"D\",):\n                df = df.with_columns(pl.col(col).cast(pl.Date))\n                if col not in self.date_cols:\n                    self.date_cols.append(col)\n                \n        return df\n\n    def feature_engineer_dates(self,df):\n        for col in self.date_cols:\n            if col in df.columns:\n                df = df.with_columns((pl.col(\"date_decision\") - pl.col(col)).dt.total_days().alias(f'{col}_DAYS_SINCE'))  # days since\n                df = df.drop(col)\n        \n        return df\n    \n    def create_base_dataset(self):\n        \n        # load in the training dataset \n        if self.n_samples:\n            train = pl.read_parquet(f\"{self.parent_path}/parquet_files/train/train_base.parquet\") \\\n            .pipe(self.set_table_dtypes).sample(n=self.n_samples).with_columns(pl.lit('train').alias('partition'))\n        else:\n            train = pl.read_parquet(f\"{self.parent_path}/parquet_files/train/train_base.parquet\") \\\n            .pipe(self.set_table_dtypes).with_columns(pl.lit('train').alias('partition'))\n        \n        # load in the test dataset\n        test =  pl.read_parquet(f\"{self.parent_path}/parquet_files/test/test_base.parquet\")\\\n                .pipe(self.set_table_dtypes).with_columns(pl.lit('test').alias('partition'))\n        \n        # concat train and test\n        self.df = pl.concat([train,test],how='diagonal_relaxed')\n        \n        # get all case_ids\n        self.case_ids = self.df.get_column('case_id').to_list()\n        \n        # make a year month\n        self.df = self.df.with_columns(self.df['date_decision'].dt.strftime(\"%Y-%m-01\").cast(pl.Date).alias(\"ym_decision\"))\n        \n\n    def read_in_files_with_criteria(self, criteria:str):\n        train_df  = pl.concat([pl.read_parquet(f\"{self.parent_path}/parquet_files/train/{x}\").pipe(self.set_table_dtypes).filter(pl.col('case_id').is_in(self.case_ids))\n                       for x in os.listdir(f\"{self.parent_path}/parquet_files/train\") if (criteria in x)],how='diagonal_relaxed')\n        test_df  =  pl.concat([pl.read_parquet(f\"{self.parent_path}/parquet_files/test/{x}\").pipe(self.set_table_dtypes)\n                       for x in os.listdir(f\"{self.parent_path}/parquet_files/test\") if (criteria in x)],how='diagonal_relaxed')\n        \n        # being in train partition doesnt gaurentee it is in the test partition, so we have to ensure it \n        columns_in_common = list(set(train_df.columns).intersection(test_df.columns))\n        \n        df = pl.concat([train_df.select(columns_in_common),\n                         test_df.select(columns_in_common)],how='diagonal_relaxed')\n        \n        \n        return df\n\n    \n    def process_depth0(self):\n        \"\"\"\n        These files can be used as is except for the dates, so just collect them, do feature engineering on the dates, then \n        throw out the date columns\n        \"\"\"\n        depth0_criterias = [\"static_0\",\"static_cb_0\"]\n        for criteria in depth0_criterias:\n            self.df = self.df.join(self.read_in_files_with_criteria(criteria), on='case_id', how='left')\n        \n        self.df = self.feature_engineer_dates(self.df)\n        self.date_cols = []\n    \n\n    def evaluate_features(self):\n        feats = self.df.columns[7:]\n        year_months = self.df['ym_decision'].unique().sort().to_list()\n        df = self.df.filter(pl.col(\"partition\")==\"train\")\n        \n        \n        # predictive power - woe*iv\n        woeivs  = []\n        for col in feats:\n            if col in self.string_cols:\n                woeiv = calculate_woe_iv_categorical(df[col].to_pandas(), df['target'].to_pandas())\n                woeivs.append(woeiv)\n            else:\n                woeiv = calculate_woe_iv_numeric(df[col].to_pandas(), df['target'].to_pandas())\n                woeivs.append(woeiv)\n\n        \n#         # stability - psi and woe*iv\n#         psi_res = {x:[] for x in feats}\n#         woe_res = {x:[] for x in feats}\n#         for i in range(len(year_months)-1):\n#             psis = []\n#             old = df.filter((pl.col(\"ym_decision\") == year_months[i]))\n#             new = df.filter((pl.col(\"ym_decision\") == year_months[i+1]))\n#             for col in feats:\n#                 if col in self.string_cols:\n#                     psi = calculate_psi_categorical(old[col].to_pandas(),new[col].to_pandas())\n#                 else:\n#                     psi = calculate_psi_numeric(old[col].to_pandas(),new[col].to_pandas())\n                    \n#                 psi_res[col].append(psi)\n                    \n\n\n            \n        self.feature_scores = pd.DataFrame(feats,columns=['feature'])\n        self.feature_scores['prop_null'] = self.feature_scores['feature'].apply(lambda feat: self.df[feat].to_pandas().isna().sum()) / len(self.df)\n        self.feature_scores['woe_iv'] = woeivs\n#         self.feature_scores['eligible_psi'] = self.feature_scores['feature'].apply(lambda feat: sum([0 if np.isnan(x) else 1 for x in psi_res[feat]]))\n#         self.feature_scores['avg_psi'] = self.feature_scores['feature'].apply(lambda feat: np.nanmean(psi_res[feat]))\n#         self.feature_scores['std_psi'] = self.feature_scores['feature'].apply(lambda feat: np.nanstd(psi_res[feat]))\n#         self.feature_scores['max_psi'] = self.feature_scores['feature'].apply(lambda feat: np.max(psi_res[feat]))\n        self.feature_scores = self.feature_scores.sort_values(['woe_iv'],ascending=[False])\n        \n    \n    def select_features(self,score=\"woe_iv\",top_k=100):\n        self.chosen_features = self.feature_scores.sort_values(score,ascending=False).reset_index(drop=True).loc[:top_k,'feature'].to_list()\n    \n        \n    def run(self):\n        self.create_base_dataset()\n        self.process_depth0()\n        self.evaluate_features()\n        self.select_features()\n    \n    def to_pandas(self,df_data, cat_cols=None):\n        df_data = df_data.to_pandas()\n        if cat_cols is None:\n            cat_cols = list(df_data.select_dtypes(\"object\").columns)\n        df_data[cat_cols] = df_data[cat_cols].astype(\"category\")\n        return df_data, cat_cols\n    \n    def get_datasets(self):\n        ds,_ = self.to_pandas(self.df)\n        return {\"train\":ds[ds['partition']=='train'].reset_index(drop=True), \n                \"test\": ds[ds['partition']=='test'].reset_index(drop=True), \n                \"features\": self.chosen_features}","metadata":{"execution":{"iopub.status.busy":"2024-05-10T00:44:28.977936Z","iopub.execute_input":"2024-05-10T00:44:28.978877Z","iopub.status.idle":"2024-05-10T00:44:29.018970Z","shell.execute_reply.started":"2024-05-10T00:44:28.978806Z","shell.execute_reply":"2024-05-10T00:44:29.017248Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"ds = DatasetBuilder().get_datasets()\nds['train']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds['train']['target'].value_counts(normalize=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training XGBoost","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import  roc_auc_score\nfrom sklearn.model_selection import train_test_split,StratifiedKFold\nimport xgboost as xgb\nfrom hyperopt import fmin, tpe, hp, SparkTrials, STATUS_OK\nfrom hyperopt.pyll import scope\nfrom functools import partial","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gini_stability(base, w_fallingrate=88.0, w_resstd=-0.5):\n    gini_in_time = base.loc[:, [\"WEEK_NUM\", \"target\", \"score\"]]\\\n        .sort_values(\"WEEK_NUM\")\\\n        .groupby(\"WEEK_NUM\")[[\"target\", \"score\"]]\\\n        .apply(lambda x: 2*roc_auc_score(x[\"target\"], x[\"score\"])-1).tolist()\n    \n    x = np.arange(len(gini_in_time))\n    y = gini_in_time\n    a, b = np.polyfit(x, y, 1)\n    y_hat = a*x + b\n    residuals = y - y_hat\n    res_std = np.std(residuals)\n    avg_gini = np.mean(gini_in_time)\n    return avg_gini + w_fallingrate * min(0, a) + w_resstd * res_std","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"search_space = {\n'colsample_bylevel': hp.uniform('colsample_bylevel', 0.5, 1),\n'colsample_bynode': hp.uniform('colsample_bynode', 0.5, 1),\n'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n'gamma': hp.loguniform('gamma',np.log(.00001), np.log(10000)),\n'max_depth': scope.int(hp.uniform('max_depth', 5, 20)),\n'min_child_weight': hp.loguniform('min_child_weight', np.log(.00001), np.log(10000)),\n'reg_alpha': hp.loguniform('reg_alpha', np.log(.00001), np.log(10000)),\n'reg_lambda':hp.loguniform('reg_lambda',np.log(.00001), np.log(10000)),\n'subsample': hp.uniform('subsample', 0.5, 1),\n'learning_rate' : hp.loguniform('learning_rate', np.log(.00001), np.log(.5)),\n'n_estimators':scope.int(hp.uniform('n_estimators', 100, 1000)),\n'tree_method':'hist',\n'enable_categorical':True,\n'random_state': 185\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def trial_fn(params,\n             feats = [],\n             ds = [],\n             k_folds=5):\n    skf = StratifiedKFold(n_splits=k_folds)\n    idx = np.arange(len(ds))\n    cumulative_score = 0\n    cumulative_n = 0\n    for train_idx, valid_idx in skf.split(idx,ds['target']):\n        train, valid = ds.loc[train_idx,:], ds.loc[valid_idx,:]\n        mod = xgb.XGBClassifier(**params)\n        mod.fit(train[feats], train['target'])\n        valid['score'] = mod.predict_proba(valid[feats])[:,1] # p(Y=1|X)\n        try:\n            cumulative_score += gini_stability(valid)\n            cumulative_n += 1\n        except:\n            continue\n            \n    avg_score = cumulative_score / cumulative_n\n    return {\"status\": STATUS_OK, \"loss\": avg_score}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_params = fmin(fn=partial(trial_fn, feats = ds['features'], ds = ds['train']),\n                    space=search_space,\n                    algo=tpe.suggest,\n                    max_evals=5,\n                    timeout=60*60 # seconds\n                  )\nint_params = ['max_depth','n_estimators']\nfor k,v in best_params.items():\n    best_params[k] = int(best_params[k])\n\n\n# best_params = {\"enable_categorical\":True}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mod = xgb.XGBClassifier(**best_params)\nmod.fit(ds['train'][ds['features']], ds['train']['target'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission\n","metadata":{}},{"cell_type":"code","source":"ds['test']['score'] = mod.predict_proba(ds['test'][ds['features']])[:,1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = ds['test'][['case_id','score']]\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}