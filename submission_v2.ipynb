{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":50160,"databundleVersionId":7921029,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport polars as pl\nimport os, gc, warnings\nfrom glob import glob\nfrom pathlib import Path\nfrom typing import Any\nfrom itertools import combinations, permutations\nfrom tqdm import tqdm\n\nwarnings.filterwarnings(\"ignore\")\n\nROOT = Path(\"/kaggle/input/home-credit-credit-risk-model-stability\")\nTRAIN_DIR = ROOT / \"parquet_files\" / \"train\"\nTEST_DIR = ROOT / \"parquet_files\" / \"test\"","metadata":{"execution":{"iopub.status.busy":"2024-05-21T01:37:35.663187Z","iopub.execute_input":"2024-05-21T01:37:35.663826Z","iopub.status.idle":"2024-05-21T01:37:36.373926Z","shell.execute_reply.started":"2024-05-21T01:37:35.663774Z","shell.execute_reply":"2024-05-21T01:37:36.372542Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# preprocessing","metadata":{}},{"cell_type":"code","source":"class Utility:\n    @staticmethod\n    def get_feat_defs(ending_with: str) -> None:\n        \"\"\"\n        Retrieves feature definitions from a CSV file based on the specified ending.\n\n        Args:\n        - ending_with (str): Ending to filter feature definitions.\n\n        Returns:\n        - pl.DataFrame: Filtered feature definitions.\n        \"\"\"\n        feat_defs: pl.DataFrame = pl.read_csv(ROOT / \"feature_definitions.csv\")\n\n        filtered_feats: pl.DataFrame = feat_defs.filter(\n            pl.col(\"Variable\").apply(lambda var: var.endswith(ending_with))\n        )\n\n        with pl.Config(fmt_str_lengths=200, tbl_rows=-1):\n            print(filtered_feats)\n\n        filtered_feats = None\n        feat_defs = None\n\n    @staticmethod\n    def find_index(lst: list[Any], item: Any) -> int | None:\n        \"\"\"\n        Finds the index of an item in a list.\n\n        Args:\n        - lst (list): List to search.\n        - item (Any): Item to find in the list.\n\n        Returns:\n        - int | None: Index of the item if found, otherwise None.\n        \"\"\"\n        try:\n            return lst.index(item)\n        except ValueError:\n            return None\n\n    @staticmethod\n    def dtype_to_str(dtype: pl.DataType) -> str:\n        \"\"\"\n        Converts Polars data type to string representation.\n\n        Args:\n        - dtype (pl.DataType): Polars data type.\n\n        Returns:\n        - str: String representation of the data type.\n        \"\"\"\n        dtype_map = {\n            pl.Decimal: \"Decimal\",\n            pl.Float32: \"Float32\",\n            pl.Float64: \"Float64\",\n            pl.UInt8: \"UInt8\",\n            pl.UInt16: \"UInt16\",\n            pl.UInt32: \"UInt32\",\n            pl.UInt64: \"UInt64\",\n            pl.Int8: \"Int8\",\n            pl.Int16: \"Int16\",\n            pl.Int32: \"Int32\",\n            pl.Int64: \"Int64\",\n            pl.Date: \"Date\",\n            pl.Datetime: \"Datetime\",\n            pl.Duration: \"Duration\",\n            pl.Time: \"Time\",\n            pl.Array: \"Array\",\n            pl.List: \"List\",\n            pl.Struct: \"Struct\",\n            pl.String: \"String\",\n            pl.Categorical: \"Categorical\",\n            pl.Enum: \"Enum\",\n            pl.Utf8: \"Utf8\",\n            pl.Binary: \"Binary\",\n            pl.Boolean: \"Boolean\",\n            pl.Null: \"Null\",\n            pl.Object: \"Object\",\n            pl.Unknown: \"Unknown\",\n        }\n\n        return dtype_map.get(dtype)\n\n    @staticmethod\n    def find_feat_occur(regex_path: str, ending_with: str) -> pl.DataFrame:\n        \"\"\"\n        Finds occurrences of features ending with a specific string in Parquet files.\n\n        Args:\n        - regex_path (str): Regular expression to match Parquet file paths.\n        - ending_with (str): Ending to filter feature names.\n\n        Returns:\n        - pl.DataFrame: DataFrame containing feature definitions, data types, and file locations.\n        \"\"\"\n        feat_defs: pl.DataFrame = pl.read_csv(ROOT / \"feature_definitions.csv\").filter(\n            pl.col(\"Variable\").apply(lambda var: var.endswith(ending_with))\n        )\n        feat_defs.sort(by=[\"Variable\"])\n\n        feats: list[pl.String] = feat_defs[\"Variable\"].to_list()\n        feats.sort()\n\n        occurrences: list[list] = [[set(), set()] for _ in range(feat_defs.height)]\n\n        for path in glob(str(regex_path)):\n            df_schema: dict = pl.read_parquet_schema(path)\n\n            for feat, dtype in df_schema.items():\n                index: int = Utility.find_index(feats, feat)\n                if index != None:\n                    occurrences[index][0].add(Utility.dtype_to_str(dtype))\n                    occurrences[index][1].add(Path(path).stem)\n\n        data_types: list[str] = [None] * feat_defs.height\n        file_locs: list[str] = [None] * feat_defs.height\n\n        for i, feat in enumerate(feats):\n            data_types[i] = list(occurrences[i][0])\n            file_locs[i] = list(occurrences[i][1])\n\n        feat_defs = feat_defs.with_columns(pl.Series(data_types).alias(\"Data_Type(s)\"))\n        feat_defs = feat_defs.with_columns(pl.Series(file_locs).alias(\"File_Loc(s)\"))\n\n        return feat_defs\n\n    def reduce_memory_usage(df: pl.DataFrame, name) -> pl.DataFrame:\n        \"\"\"\n        Reduces memory usage of a DataFrame by converting column types.\n\n        Args:\n        - df (pl.DataFrame): DataFrame to optimize.\n        - name (str): Name of the DataFrame.\n\n        Returns:\n        - pl.DataFrame: Optimized DataFrame.\n        \"\"\"\n        print(\n            f\"Memory usage of dataframe \\\"{name}\\\" is {round(df.estimated_size('mb'), 4)} MB.\"\n        )\n\n        int_types = [\n            pl.Int8,\n            pl.Int16,\n            pl.Int32,\n            pl.Int64,\n            pl.UInt8,\n            pl.UInt16,\n            pl.UInt32,\n            pl.UInt64,\n        ]\n        float_types = [pl.Float32, pl.Float64]\n\n        for col in df.columns:\n            col_type = df[col].dtype\n            if col_type in int_types + float_types:\n                c_min = df[col].min()\n                c_max = df[col].max()\n\n                if c_min is not None and c_max is not None:\n                    if col_type in int_types:\n                        if c_min >= 0:\n                            if (\n                                c_min >= np.iinfo(np.uint8).min\n                                and c_max <= np.iinfo(np.uint8).max\n                            ):\n                                df = df.with_columns(df[col].cast(pl.UInt8))\n                            elif (\n                                c_min >= np.iinfo(np.uint16).min\n                                and c_max <= np.iinfo(np.uint16).max\n                            ):\n                                df = df.with_columns(df[col].cast(pl.UInt16))\n                            elif (\n                                c_min >= np.iinfo(np.uint32).min\n                                and c_max <= np.iinfo(np.uint32).max\n                            ):\n                                df = df.with_columns(df[col].cast(pl.UInt32))\n                            elif (\n                                c_min >= np.iinfo(np.uint64).min\n                                and c_max <= np.iinfo(np.uint64).max\n                            ):\n                                df = df.with_columns(df[col].cast(pl.UInt64))\n                        else:\n                            if (\n                                c_min >= np.iinfo(np.int8).min\n                                and c_max <= np.iinfo(np.int8).max\n                            ):\n                                df = df.with_columns(df[col].cast(pl.Int8))\n                            elif (\n                                c_min >= np.iinfo(np.int16).min\n                                and c_max <= np.iinfo(np.int16).max\n                            ):\n                                df = df.with_columns(df[col].cast(pl.Int16))\n                            elif (\n                                c_min >= np.iinfo(np.int32).min\n                                and c_max <= np.iinfo(np.int32).max\n                            ):\n                                df = df.with_columns(df[col].cast(pl.Int32))\n                            elif (\n                                c_min >= np.iinfo(np.int64).min\n                                and c_max <= np.iinfo(np.int64).max\n                            ):\n                                df = df.with_columns(df[col].cast(pl.Int64))\n                    elif col_type in float_types:\n                        if (\n                            c_min > np.finfo(np.float32).min\n                            and c_max < np.finfo(np.float32).max\n                        ):\n                            df = df.with_columns(df[col].cast(pl.Float32))\n\n        print(\n            f\"Memory usage of dataframe \\\"{name}\\\" became {round(df.estimated_size('mb'), 4)} MB.\"\n        )\n\n        return df\n\n    def to_pandas(df: pl.DataFrame, cat_cols: list[str] = None) -> (pd.DataFrame, list[str]):  # type: ignore\n        \"\"\"\n        Converts a Polars DataFrame to a Pandas DataFrame.\n\n        Args:\n        - df (pl.DataFrame): Polars DataFrame to convert.\n        - cat_cols (list[str]): List of categorical columns. Default is None.\n\n        Returns:\n        - (pd.DataFrame, list[str]): Tuple containing the converted Pandas DataFrame and categorical columns.\n        \"\"\"\n        df: pd.DataFrame = df.to_pandas()\n\n        if cat_cols is None:\n            cat_cols = list(df.select_dtypes(\"object\").columns)\n\n        df[cat_cols] = df[cat_cols].astype(\"category\")\n\n        return df, cat_cols","metadata":{"execution":{"iopub.status.busy":"2024-05-21T01:37:36.376409Z","iopub.execute_input":"2024-05-21T01:37:36.376952Z","iopub.status.idle":"2024-05-21T01:37:36.410470Z","shell.execute_reply.started":"2024-05-21T01:37:36.376914Z","shell.execute_reply":"2024-05-21T01:37:36.409117Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class Aggregator:\n    @staticmethod\n    def max_expr(df: pl.LazyFrame) -> list[pl.Series]:\n        \"\"\"\n        Generates expressions for calculating maximum values for specific columns.\n\n        Args:\n        - df (pl.LazyFrame): Input LazyFrame.\n\n        Returns:\n        - list[pl.Series]: List of expressions for maximum values.\n        \"\"\"\n        cols: list[str] = [\n            col\n            for col in df.columns\n            if (col[-1] in (\"P\", \"M\", \"A\", \"D\", \"T\", \"L\")) or (\"num_group\" in col)\n        ]\n\n        expr_max: list[pl.Series] = [\n            pl.col(col).max().alias(f\"{col}_MAX\") for col in cols\n        ]\n\n        return expr_max\n\n    @staticmethod\n    def min_expr(df: pl.LazyFrame) -> list[pl.Series]:\n        \"\"\"\n        Generates expressions for calculating minimum values for specific columns.\n\n        Args:\n        - df (pl.LazyFrame): Input LazyFrame.\n\n        Returns:\n        - list[pl.Series]: List of expressions for minimum values.\n        \"\"\"\n        cols: list[str] = [\n            col\n            for col in df.columns\n            if (col[-1] in (\"P\", \"M\", \"A\", \"D\", \"T\", \"L\")) or (\"num_group\" in col)\n        ]\n\n        expr_min: list[pl.Series] = [\n            pl.col(col).min().alias(f\"{col}_MIN\") for col in cols\n        ]\n\n        return expr_min\n\n    @staticmethod\n    def mean_expr(df: pl.LazyFrame) -> list[pl.Series]:\n        \"\"\"\n        Generates expressions for calculating mean values for specific columns.\n\n        Args:\n        - df (pl.LazyFrame): Input LazyFrame.\n\n        Returns:\n        - list[pl.Series]: List of expressions for mean values.\n        \"\"\"\n        cols: list[str] = [col for col in df.columns if col.endswith((\"P\", \"A\", \"D\"))]\n\n        expr_mean: list[pl.Series] = [\n            pl.col(col).mean().alias(f\"{col}_MEAN\") for col in cols\n        ]\n\n        return expr_mean\n\n    @staticmethod\n    def var_expr(df: pl.LazyFrame) -> list[pl.Series]:\n        \"\"\"\n        Generates expressions for calculating variance for specific columns.\n\n        Args:\n        - df (pl.LazyFrame): Input LazyFrame.\n\n        Returns:\n        - list[pl.Series]: List of expressions for variance.\n        \"\"\"\n        cols: list[str] = [col for col in df.columns if col.endswith((\"P\", \"A\", \"D\"))]\n\n        expr_mean: list[pl.Series] = [\n            pl.col(col).var().alias(f\"{col}_VAR\") for col in cols\n        ]\n\n        return expr_mean\n\n    @staticmethod\n    def mode_expr(df: pl.LazyFrame) -> list[pl.Series]:\n        \"\"\"\n        Generates expressions for calculating mode values for specific columns.\n\n        Args:\n        - df (pl.LazyFrame): Input LazyFrame.\n\n        Returns:\n        - list[pl.Series]: List of expressions for mode values.\n        \"\"\"\n        cols: list[str] = [col for col in df.columns if col.endswith(\"M\")]\n\n        expr_mode: list[pl.Series] = [\n            pl.col(col).drop_nulls().mode().first().alias(f\"{col}_MODE\") for col in cols\n        ]\n\n        return expr_mode\n\n    @staticmethod\n    def get_exprs(df: pl.LazyFrame) -> list[pl.Series]:\n        \"\"\"\n        Combines expressions for maximum, mean, and variance calculations.\n\n        Args:\n        - df (pl.LazyFrame): Input LazyFrame.\n\n        Returns:\n        - list[pl.Series]: List of combined expressions.\n        \"\"\"\n        exprs = (\n            Aggregator.max_expr(df) + Aggregator.mean_expr(df) + Aggregator.var_expr(df)\n        )\n\n        return exprs","metadata":{"execution":{"iopub.status.busy":"2024-05-21T01:37:36.412273Z","iopub.execute_input":"2024-05-21T01:37:36.412945Z","iopub.status.idle":"2024-05-21T01:37:36.431124Z","shell.execute_reply.started":"2024-05-21T01:37:36.412897Z","shell.execute_reply":"2024-05-21T01:37:36.429531Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class SchemaGen:\n    @staticmethod\n    def change_dtypes(df: pl.LazyFrame) -> pl.LazyFrame:\n        \"\"\"\n        Changes the data types of columns in the DataFrame.\n\n        Args:\n        - df (pl.LazyFrame): Input LazyFrame.\n\n        Returns:\n        - pl.LazyFrame: LazyFrame with modified data types.\n        \"\"\"\n        for col in df.columns:\n            if col == \"case_id\":\n                df = df.with_columns(pl.col(col).cast(pl.UInt32).alias(col))\n            elif col in [\"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n                df = df.with_columns(pl.col(col).cast(pl.UInt16).alias(col))\n            elif col == \"date_decision\" or col[-1] == \"D\":\n                df = df.with_columns(pl.col(col).cast(pl.Date).alias(col))\n            elif col[-1] in [\"P\", \"A\"]:\n                df = df.with_columns(pl.col(col).cast(pl.Float64).alias(col))\n            elif col[-1] in (\"M\",):\n                df = df.with_columns(pl.col(col).cast(pl.String))\n        return df\n\n    @staticmethod\n    def scan_files(glob_path: str, depth: int = None):\n        chunks = []\n        for path in glob(str(glob_path)):\n            df = pl.read_parquet(path, low_memory=True, rechunk=True)\n            df = df.pipe(SchemaGen.change_dtypes)\n            if depth in [1, 2]:\n                df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n            chunks.append(df)\n        df = pl.concat(chunks, how=\"vertical_relaxed\")\n        del chunks\n        gc.collect()\n\n        df = df.unique(subset=[\"case_id\"]) \n        \n        return df\n\n    @staticmethod\n    def join_dataframes(df_base, depth_0, depth_1, depth_2):\n        for i, df in enumerate(depth_0 + depth_1 + depth_2):\n            df_base = df_base.join(df, how=\"left\", on=\"case_id\", suffix=f\"_{i}\")\n        return df_base\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T01:37:36.434911Z","iopub.execute_input":"2024-05-21T01:37:36.435484Z","iopub.status.idle":"2024-05-21T01:37:36.451977Z","shell.execute_reply.started":"2024-05-21T01:37:36.435413Z","shell.execute_reply":"2024-05-21T01:37:36.450380Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def filter_cols(df: pl.DataFrame) -> pl.DataFrame:\n    \"\"\"\n    Filters columns in the DataFrame based on null percentage and unique values for string columns.\n\n    Args:\n    - df (pl.DataFrame): Input DataFrame.\n\n    Returns:\n    - pl.DataFrame: DataFrame with filtered columns.\n    \"\"\"\n    for col in df.columns:\n        if col not in [\"case_id\", \"year\", \"month\", \"week_num\", \"target\"]:\n            null_pct = df[col].is_null().mean()\n\n            if null_pct > 0.95:\n                df = df.drop(col)\n\n    for col in df.columns:\n        if (col not in [\"case_id\", \"year\", \"month\", \"week_num\", \"target\"]) & (\n            df[col].dtype == pl.String\n        ):\n            freq = df[col].n_unique()\n\n            if (freq > 200) | (freq == 1):\n                df = df.drop(col)\n\n    return df\n\n\ndef transform_cols(df: pl.DataFrame) -> pl.DataFrame:\n    \"\"\"\n    Transforms columns in the DataFrame according to predefined rules.\n\n    Args:\n    - df (pl.DataFrame): Input DataFrame.\n\n    Returns:\n    - pl.DataFrame: DataFrame with transformed columns.\n    \"\"\"\n    if \"riskassesment_302T\" in df.columns:\n        if df[\"riskassesment_302T\"].dtype == pl.Null:\n            df = df.with_columns(\n                [\n                    pl.Series(\n                        \"riskassesment_302T_rng\", df[\"riskassesment_302T\"], pl.UInt8\n                    ),\n                    pl.Series(\n                        \"riskassesment_302T_mean\", df[\"riskassesment_302T\"], pl.UInt8\n                    ),\n                ]\n            )\n        else:\n            pct_low: pl.Series = (\n                df[\"riskassesment_302T\"]\n                .str.split(\" - \")\n                .apply(lambda x: x[0].replace(\"%\", \"\"))\n                .cast(pl.UInt8)\n            )\n            pct_high: pl.Series = (\n                df[\"riskassesment_302T\"]\n                .str.split(\" - \")\n                .apply(lambda x: x[1].replace(\"%\", \"\"))\n                .cast(pl.UInt8)\n            )\n\n            diff: pl.Series = pct_high - pct_low\n            avg: pl.Series = ((pct_low + pct_high) / 2).cast(pl.Float32)\n\n            del pct_high, pct_low\n            gc.collect()\n\n            df = df.with_columns(\n                [\n                    diff.alias(\"riskassesment_302T_rng\"),\n                    avg.alias(\"riskassesment_302T_mean\"),\n                ]\n            )\n\n        df.drop(\"riskassesment_302T\")\n\n    return df\n\n\ndef handle_dates(df: pl.DataFrame) -> pl.DataFrame:\n    \"\"\"\n    Handles date columns in the DataFrame.\n\n    Args:\n    - df (pl.DataFrame): Input DataFrame.\n\n    Returns:\n    - pl.DataFrame: DataFrame with transformed date columns.\n    \"\"\"\n    for col in df.columns:\n        if (col[-1] == 'D') or ('D_' in col):\n            df = df.with_columns(pl.col(col) - pl.col(\"date_decision\"))\n            df = df.with_columns(pl.col(col).dt.total_days().cast(pl.Int32))\n\n    df = df.rename(\n        {\n            \"MONTH\": \"month\",\n            \"WEEK_NUM\": \"week_num\"\n        }\n    )\n            \n    df = df.with_columns(\n        [\n            pl.col(\"date_decision\").dt.year().alias(\"year\").cast(pl.Int16),\n            pl.col(\"date_decision\").dt.day().alias(\"day\").cast(pl.UInt8),\n        ]\n    )\n\n    df = df.drop(\"date_decision\")\n    df = df.drop(\"month\")\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-05-21T01:37:36.453803Z","iopub.execute_input":"2024-05-21T01:37:36.454159Z","iopub.status.idle":"2024-05-21T01:37:36.475947Z","shell.execute_reply.started":"2024-05-21T01:37:36.454128Z","shell.execute_reply":"2024-05-21T01:37:36.474565Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def reduce_group(grps):\n    use = []\n    for g in grps:\n        mx = 0; vx = g[0]\n        for gg in g:\n            n = df_train[gg].nunique()\n            if n>mx:\n                mx = n\n                vx = gg\n        use.append(vx)\n    return use\n\ndef group_columns_by_correlation(matrix, threshold=0.8):\n    correlation_matrix = matrix.corr()\n    groups = []\n    remaining_cols = list(matrix.columns)\n    while remaining_cols:\n        col = remaining_cols.pop(0)\n        group = [col]\n        correlated_cols = [col]\n        for c in remaining_cols:\n            if correlation_matrix.loc[col, c] >= threshold:\n                group.append(c)\n                correlated_cols.append(c)\n        groups.append(group)\n        remaining_cols = [c for c in remaining_cols if c not in correlated_cols]\n    \n    return groups","metadata":{"execution":{"iopub.status.busy":"2024-05-21T01:37:36.477484Z","iopub.execute_input":"2024-05-21T01:37:36.478236Z","iopub.status.idle":"2024-05-21T01:37:36.491892Z","shell.execute_reply.started":"2024-05-21T01:37:36.478189Z","shell.execute_reply":"2024-05-21T01:37:36.490673Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data_store: dict = {\n    \"df_base\": SchemaGen.scan_files(TRAIN_DIR / \"train_base.parquet\"),\n    \"depth_0\": [\n        SchemaGen.scan_files(TRAIN_DIR / \"train_static_cb_0.parquet\"),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_static_0_*.parquet\"),\n    ],\n    \"depth_1\": [\n        SchemaGen.scan_files(TRAIN_DIR / \"train_applprev_1_*.parquet\", 1),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_tax_registry_a_1.parquet\", 1),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_tax_registry_b_1.parquet\", 1),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_tax_registry_c_1.parquet\", 1),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_credit_bureau_a_1_*.parquet\", 1),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_credit_bureau_b_1.parquet\", 1),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_other_1.parquet\", 1),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_person_1.parquet\", 1),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_deposit_1.parquet\", 1),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_debitcard_1.parquet\", 1),\n    ],\n    \"depth_2\": [\n        SchemaGen.scan_files(TRAIN_DIR / \"train_credit_bureau_a_2_*.parquet\", 2),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_credit_bureau_b_2.parquet\", 2),\n    ],\n}\n\ndf_train: pl.DataFrame = (\n    SchemaGen.join_dataframes(**data_store)\n    .pipe(filter_cols)\n    .pipe(transform_cols)\n    .pipe(handle_dates)\n    .pipe(Utility.reduce_memory_usage, \"df_train\")\n)\n\ndel data_store\ngc.collect()\n\nprint(f\"Train data shape: {df_train.shape}\")\ndisplay(df_train.head(10))","metadata":{"execution":{"iopub.status.busy":"2024-05-21T01:37:36.493585Z","iopub.execute_input":"2024-05-21T01:37:36.494000Z","iopub.status.idle":"2024-05-21T01:40:52.557893Z","shell.execute_reply.started":"2024-05-21T01:37:36.493964Z","shell.execute_reply":"2024-05-21T01:40:52.556588Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Memory usage of dataframe \"df_train\" is 4699.5721 MB.\nMemory usage of dataframe \"df_train\" became 2659.8065 MB.\nTrain data shape: (1526659, 471)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"shape: (10, 471)\n┌─────────┬──────────┬────────┬─────────────────┬───┬────────────────┬────────────────┬──────┬─────┐\n│ case_id ┆ week_num ┆ target ┆ assignmentdate_ ┆ … ┆ pmts_overdue_1 ┆ pmts_overdue_1 ┆ year ┆ day │\n│ ---     ┆ ---      ┆ ---    ┆ 238D            ┆   ┆ 140A_VAR       ┆ 152A_VAR       ┆ ---  ┆ --- │\n│ u32     ┆ u8       ┆ u8     ┆ ---             ┆   ┆ ---            ┆ ---            ┆ u16  ┆ u8  │\n│         ┆          ┆        ┆ i16             ┆   ┆ f32            ┆ f32            ┆      ┆     │\n╞═════════╪══════════╪════════╪═════════════════╪═══╪════════════════╪════════════════╪══════╪═════╡\n│ 633272  ┆ 6        ┆ 0      ┆ null            ┆ … ┆ 1.12599512e8   ┆ null           ┆ 2019 ┆ 16  │\n│ 1839502 ┆ 71       ┆ 0      ┆ null            ┆ … ┆ 9.177756e7     ┆ 2.1494e6       ┆ 2020 ┆ 13  │\n│ 238999  ┆ 81       ┆ 0      ┆ null            ┆ … ┆ 1.0407e6       ┆ 1.8857e6       ┆ 2020 ┆ 21  │\n│ 1663056 ┆ 47       ┆ 0      ┆ null            ┆ … ┆ 0.0            ┆ 25379.642578   ┆ 2019 ┆ 2   │\n│ 2544202 ┆ 7        ┆ 0      ┆ -5026           ┆ … ┆ 0.0            ┆ null           ┆ 2019 ┆ 19  │\n│ 1725049 ┆ 52       ┆ 0      ┆ null            ┆ … ┆ null           ┆ 308465.21875   ┆ 2019 ┆ 31  │\n│ 891486  ┆ 48       ┆ 0      ┆ null            ┆ … ┆ 0.0            ┆ null           ┆ 2019 ┆ 8   │\n│ 620354  ┆ 3        ┆ 0      ┆ null            ┆ … ┆ null           ┆ null           ┆ 2019 ┆ 27  │\n│ 990737  ┆ 75       ┆ 0      ┆ null            ┆ … ┆ null           ┆ null           ┆ 2020 ┆ 10  │\n│ 812716  ┆ 38       ┆ 0      ┆ null            ┆ … ┆ 0.0            ┆ 629034.1875    ┆ 2019 ┆ 26  │\n└─────────┴──────────┴────────┴─────────────────┴───┴────────────────┴────────────────┴──────┴─────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (10, 471)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>case_id</th><th>week_num</th><th>target</th><th>assignmentdate_238D</th><th>assignmentdate_4527235D</th><th>birthdate_574D</th><th>contractssum_5085716L</th><th>dateofbirth_337D</th><th>days120_123L</th><th>days180_256L</th><th>days30_165L</th><th>days360_512L</th><th>days90_310L</th><th>description_5085714M</th><th>education_1103M</th><th>education_88M</th><th>firstquarter_103L</th><th>fourthquarter_440L</th><th>maritalst_385M</th><th>maritalst_893M</th><th>numberofqueries_373L</th><th>pmtaverage_3A</th><th>pmtaverage_4527227A</th><th>pmtcount_4527229L</th><th>pmtcount_693L</th><th>pmtscount_423L</th><th>pmtssum_45A</th><th>requesttype_4525192L</th><th>responsedate_1012D</th><th>responsedate_4527233D</th><th>responsedate_4917613D</th><th>secondquarter_766L</th><th>thirdquarter_1082L</th><th>actualdpdtolerance_344P</th><th>amtinstpaidbefduel24m_4187115A</th><th>annuity_780A</th><th>annuitynextmonth_57A</th><th>&hellip;</th><th>mainoccupationinc_384A_MEAN</th><th>amount_416A_MAX</th><th>num_group1_MAX_10</th><th>openingdate_313D_MAX</th><th>amount_416A_MEAN</th><th>openingdate_313D_MEAN</th><th>num_group1_MAX_11</th><th>openingdate_857D_MAX</th><th>openingdate_857D_MEAN</th><th>collater_typofvalofguarant_298M_MAX</th><th>collater_typofvalofguarant_407M_MAX</th><th>collater_valueofguarantee_1124L_MAX</th><th>collater_valueofguarantee_876L_MAX</th><th>collaterals_typeofguarante_359M_MAX</th><th>collaterals_typeofguarante_669M_MAX</th><th>num_group1_MAX_12</th><th>num_group2_MAX</th><th>pmts_dpd_1073P_MAX</th><th>pmts_dpd_303P_MAX</th><th>pmts_month_158T_MAX</th><th>pmts_month_706T_MAX</th><th>pmts_overdue_1140A_MAX</th><th>pmts_overdue_1152A_MAX</th><th>pmts_year_1139T_MAX</th><th>pmts_year_507T_MAX</th><th>subjectroles_name_541M_MAX</th><th>subjectroles_name_838M_MAX</th><th>pmts_dpd_1073P_MEAN</th><th>pmts_dpd_303P_MEAN</th><th>pmts_overdue_1140A_MEAN</th><th>pmts_overdue_1152A_MEAN</th><th>pmts_dpd_1073P_VAR</th><th>pmts_dpd_303P_VAR</th><th>pmts_overdue_1140A_VAR</th><th>pmts_overdue_1152A_VAR</th><th>year</th><th>day</th></tr><tr><td>u32</td><td>u8</td><td>u8</td><td>i16</td><td>u8</td><td>i16</td><td>f32</td><td>i32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>str</td><td>str</td><td>str</td><td>f32</td><td>f32</td><td>str</td><td>str</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>str</td><td>i8</td><td>u8</td><td>i8</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>&hellip;</td><td>f32</td><td>f32</td><td>u8</td><td>i16</td><td>f32</td><td>i16</td><td>u8</td><td>i16</td><td>i16</td><td>str</td><td>str</td><td>f32</td><td>f32</td><td>str</td><td>str</td><td>u16</td><td>u8</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>str</td><td>str</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>u16</td><td>u8</td></tr></thead><tbody><tr><td>633272</td><td>6</td><td>0</td><td>null</td><td>null</td><td>-16423</td><td>null</td><td>-16423</td><td>0.0</td><td>0.0</td><td>0.0</td><td>6.0</td><td>0.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>2.0</td><td>0.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>6.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>6.0</td><td>3393.600098</td><td>null</td><td>14</td><td>null</td><td>null</td><td>2.0</td><td>4.0</td><td>null</td><td>null</td><td>1513.0</td><td>0.0</td><td>&hellip;</td><td>120000.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>1.0113e7</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;c7a5ad39&quot;</td><td>4</td><td>35</td><td>78.0</td><td>null</td><td>12.0</td><td>null</td><td>44888.414062</td><td>null</td><td>2020.0</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;ab3c25cf&quot;</td><td>6.304878</td><td>null</td><td>5714.283203</td><td>null</td><td>240.337997</td><td>null</td><td>1.12599512e8</td><td>null</td><td>2019</td><td>16</td></tr><tr><td>1839502</td><td>71</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-19126</td><td>1.0</td><td>3.0</td><td>1.0</td><td>3.0</td><td>1.0</td><td>&quot;a55475b1&quot;</td><td>&quot;6b2ae0fa&quot;</td><td>&quot;a55475b1&quot;</td><td>2.0</td><td>4.0</td><td>&quot;3439d993&quot;</td><td>&quot;a55475b1&quot;</td><td>3.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>14</td><td>2.0</td><td>2.0</td><td>0.0</td><td>30607.0</td><td>6150.200195</td><td>3276.0</td><td>&hellip;</td><td>54000.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>0.0</td><td>&quot;c7a5ad39&quot;</td><td>&quot;c7a5ad39&quot;</td><td>5</td><td>35</td><td>3854.0</td><td>220.0</td><td>12.0</td><td>12.0</td><td>24174.669922</td><td>5234.624023</td><td>2021.0</td><td>2020.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;ab3c25cf&quot;</td><td>1305.909058</td><td>17.328571</td><td>6954.425293</td><td>858.877136</td><td>3048951.5</td><td>2296.774414</td><td>9.177756e7</td><td>2.1494e6</td><td>2020</td><td>13</td></tr><tr><td>238999</td><td>81</td><td>0</td><td>null</td><td>null</td><td>null</td><td>896256.1875</td><td>-14477</td><td>2.0</td><td>5.0</td><td>1.0</td><td>16.0</td><td>2.0</td><td>&quot;2fc785b2&quot;</td><td>&quot;717ddd49&quot;</td><td>&quot;a55475b1&quot;</td><td>9.0</td><td>2.0</td><td>&quot;3439d993&quot;</td><td>&quot;a55475b1&quot;</td><td>16.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>12</td><td>5.0</td><td>11.0</td><td>0.0</td><td>118177.601562</td><td>1374.800049</td><td>137.400009</td><td>&hellip;</td><td>52000.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>0.0</td><td>&quot;c7a5ad39&quot;</td><td>&quot;c7a5ad39&quot;</td><td>5</td><td>35</td><td>21.0</td><td>26.0</td><td>12.0</td><td>12.0</td><td>3879.0</td><td>4521.007812</td><td>2021.0</td><td>2020.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;ab3c25cf&quot;</td><td>1.522727</td><td>1.777778</td><td>319.399994</td><td>630.443542</td><td>16.720402</td><td>22.197254</td><td>1.0407e6</td><td>1.8857e6</td><td>2020</td><td>21</td></tr><tr><td>1663056</td><td>47</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-9285</td><td>2.0</td><td>2.0</td><td>1.0</td><td>6.0</td><td>1.0</td><td>&quot;a55475b1&quot;</td><td>&quot;6b2ae0fa&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>6.0</td><td>&quot;3439d993&quot;</td><td>&quot;a55475b1&quot;</td><td>6.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;DEDUCTION_6&quot;</td><td>null</td><td>14</td><td>null</td><td>0.0</td><td>6.0</td><td>0.0</td><td>107023.773438</td><td>6581.399902</td><td>5860.399902</td><td>&hellip;</td><td>120000.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>0.0</td><td>&quot;c7a5ad39&quot;</td><td>&quot;c7a5ad39&quot;</td><td>2</td><td>23</td><td>0.0</td><td>1.0</td><td>12.0</td><td>12.0</td><td>0.0</td><td>574.400024</td><td>2020.0</td><td>2020.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>0.076923</td><td>0.0</td><td>44.184616</td><td>0.0</td><td>0.076923</td><td>0.0</td><td>25379.642578</td><td>2019</td><td>2</td></tr><tr><td>2544202</td><td>7</td><td>0</td><td>-5026</td><td>null</td><td>-26469</td><td>null</td><td>-26469</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&quot;a55475b1&quot;</td><td>&quot;717ddd49&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>0.0</td><td>&quot;3439d993&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>5538.533203</td><td>null</td><td>null</td><td>5.0</td><td>null</td><td>null</td><td>null</td><td>14</td><td>null</td><td>null</td><td>0.0</td><td>1.0</td><td>0.0</td><td>null</td><td>6358.600098</td><td>2740.600098</td><td>&hellip;</td><td>30000.0</td><td>0.0</td><td>0</td><td>-1562</td><td>0.0</td><td>-1562</td><td>0</td><td>-1562</td><td>-1562</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;c7a5ad39&quot;</td><td>0</td><td>23</td><td>0.0</td><td>null</td><td>12.0</td><td>null</td><td>0.0</td><td>null</td><td>2020.0</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>2019</td><td>19</td></tr><tr><td>1725049</td><td>52</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-11779</td><td>6.0</td><td>6.0</td><td>3.0</td><td>21.0</td><td>5.0</td><td>&quot;a55475b1&quot;</td><td>&quot;6b2ae0fa&quot;</td><td>&quot;a55475b1&quot;</td><td>21.0</td><td>7.0</td><td>&quot;a7fcb6e5&quot;</td><td>&quot;a55475b1&quot;</td><td>21.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;DEDUCTION_6&quot;</td><td>null</td><td>14</td><td>null</td><td>4.0</td><td>4.0</td><td>0.0</td><td>125632.1875</td><td>5832.600098</td><td>0.0</td><td>&hellip;</td><td>90000.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>2.125814e7</td><td>0.0</td><td>&quot;c7a5ad39&quot;</td><td>&quot;a55475b1&quot;</td><td>11</td><td>35</td><td>0.0</td><td>3.0</td><td>12.0</td><td>12.0</td><td>0.0</td><td>6259.0</td><td>2020.0</td><td>2020.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;daf49a8a&quot;</td><td>0.0</td><td>0.023622</td><td>0.0</td><td>49.283466</td><td>null</td><td>0.070866</td><td>null</td><td>308465.21875</td><td>2019</td><td>31</td></tr><tr><td>891486</td><td>48</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-13947</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>0.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;DEDUCTION_6&quot;</td><td>null</td><td>14</td><td>null</td><td>2.0</td><td>0.0</td><td>null</td><td>null</td><td>1869.800049</td><td>0.0</td><td>&hellip;</td><td>60000.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;c7a5ad39&quot;</td><td>0</td><td>35</td><td>0.0</td><td>null</td><td>12.0</td><td>null</td><td>0.0</td><td>null</td><td>2020.0</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>2019</td><td>8</td></tr><tr><td>620354</td><td>3</td><td>0</td><td>null</td><td>null</td><td>-15580</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>6.0</td><td>14979.200195</td><td>null</td><td>14</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1772.200073</td><td>0.0</td><td>&hellip;</td><td>40000.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2019</td><td>27</td></tr><tr><td>990737</td><td>75</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>14</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2734.600098</td><td>0.0</td><td>&hellip;</td><td>30000.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2020</td><td>10</td></tr><tr><td>812716</td><td>38</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-18591</td><td>0.0</td><td>1.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>1.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>1.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>5.0</td><td>4128.600098</td><td>&quot;DEDUCTION_6&quot;</td><td>14</td><td>14</td><td>null</td><td>4.0</td><td>0.0</td><td>0.0</td><td>18684.0</td><td>2000.0</td><td>6228.0</td><td>&hellip;</td><td>36000.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>0.0</td><td>&quot;c7a5ad39&quot;</td><td>&quot;c7a5ad39&quot;</td><td>5</td><td>35</td><td>0.0</td><td>14.0</td><td>12.0</td><td>12.0</td><td>0.0</td><td>3701.917969</td><td>2020.0</td><td>2020.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>0.337349</td><td>0.0</td><td>188.610916</td><td>0.0</td><td>2.811637</td><td>0.0</td><td>629034.1875</td><td>2019</td><td>26</td></tr></tbody></table></div>"},"metadata":{}}]},{"cell_type":"code","source":"data_store: dict = {\n    \"df_base\": SchemaGen.scan_files(TEST_DIR / \"test_base.parquet\"),\n    \"depth_0\": [\n        SchemaGen.scan_files(TEST_DIR / \"test_static_cb_0.parquet\"),\n        SchemaGen.scan_files(TEST_DIR / \"test_static_0_*.parquet\"),\n    ],\n    \"depth_1\": [\n        SchemaGen.scan_files(TEST_DIR / \"test_applprev_1_*.parquet\", 1),\n        SchemaGen.scan_files(TEST_DIR / \"test_tax_registry_a_1.parquet\", 1),\n        SchemaGen.scan_files(TEST_DIR / \"test_tax_registry_b_1.parquet\", 1),\n        SchemaGen.scan_files(TEST_DIR / \"test_tax_registry_c_1.parquet\", 1),\n        SchemaGen.scan_files(TEST_DIR / \"test_credit_bureau_a_1_*.parquet\", 1),\n        SchemaGen.scan_files(TEST_DIR / \"test_credit_bureau_b_1.parquet\", 1),\n        SchemaGen.scan_files(TEST_DIR / \"test_other_1.parquet\", 1),\n        SchemaGen.scan_files(TEST_DIR / \"test_person_1.parquet\", 1),\n        SchemaGen.scan_files(TEST_DIR / \"test_deposit_1.parquet\", 1),\n        SchemaGen.scan_files(TEST_DIR / \"test_debitcard_1.parquet\", 1),\n    ],\n    \"depth_2\": [\n        SchemaGen.scan_files(TEST_DIR / \"test_credit_bureau_a_2_*.parquet\", 2),\n        SchemaGen.scan_files(TEST_DIR / \"test_credit_bureau_b_2.parquet\", 2),\n    ],\n}\n\ndf_test: pl.DataFrame = (\n    SchemaGen.join_dataframes(**data_store)\n    .pipe(transform_cols)\n    .pipe(handle_dates)\n    .select([col for col in df_train.columns if col != \"target\"])\n    .pipe(Utility.reduce_memory_usage, \"df_test\")\n)\n\ndel data_store\ngc.collect()\n\nprint(f\"Test data shape: {df_test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-21T01:40:52.559952Z","iopub.execute_input":"2024-05-21T01:40:52.560313Z","iopub.status.idle":"2024-05-21T01:40:54.160558Z","shell.execute_reply.started":"2024-05-21T01:40:52.560284Z","shell.execute_reply":"2024-05-21T01:40:54.159573Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Memory usage of dataframe \"df_test\" is 0.0297 MB.\nMemory usage of dataframe \"df_test\" became 0.0172 MB.\nTest data shape: (10, 470)\n","output_type":"stream"}]},{"cell_type":"code","source":"if 'target' not in df_test.columns:\n    df_test = df_test.with_columns(pl.lit(0).alias('target').cast(pl.Int8))","metadata":{"execution":{"iopub.status.busy":"2024-05-21T01:40:54.161879Z","iopub.execute_input":"2024-05-21T01:40:54.162877Z","iopub.status.idle":"2024-05-21T01:40:54.168085Z","shell.execute_reply.started":"2024-05-21T01:40:54.162818Z","shell.execute_reply":"2024-05-21T01:40:54.166961Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df, cat_cols = Utility.to_pandas(\n                        pl.concat([\n                                 df_train.with_columns(pl.lit('train').alias('partition')),\n                                 df_test.select(df_train.columns).with_columns(pl.lit('test').alias('partition'))\n                                    ],how='vertical_relaxed')\n                                )\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-21T01:40:54.171272Z","iopub.execute_input":"2024-05-21T01:40:54.171827Z","iopub.status.idle":"2024-05-21T01:41:13.630997Z","shell.execute_reply.started":"2024-05-21T01:40:54.171791Z","shell.execute_reply":"2024-05-21T01:41:13.629733Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(1526669, 472)"},"metadata":{}}]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-05-21T01:41:13.633340Z","iopub.execute_input":"2024-05-21T01:41:13.634246Z","iopub.status.idle":"2024-05-21T01:41:13.879674Z","shell.execute_reply.started":"2024-05-21T01:41:13.634197Z","shell.execute_reply":"2024-05-21T01:41:13.878712Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"         case_id  week_num  target  assignmentdate_238D  \\\n0         633272         6       0                  NaN   \n1        1839502        71       0                  NaN   \n2         238999        81       0                  NaN   \n3        1663056        47       0                  NaN   \n4        2544202         7       0              -5026.0   \n...          ...       ...     ...                  ...   \n1526664    57631       100       0                  NaN   \n1526665    57634       100       0                  NaN   \n1526666    57630       100       0                  NaN   \n1526667    57569       100       0                  NaN   \n1526668    57549       100       0                  NaN   \n\n         assignmentdate_4527235D  birthdate_574D  contractssum_5085716L  \\\n0                            NaN        -16423.0                    NaN   \n1                            NaN             NaN                    NaN   \n2                            NaN             NaN           8.962562e+05   \n3                            NaN             NaN                    NaN   \n4                            NaN        -26469.0                    NaN   \n...                          ...             ...                    ...   \n1526664                      NaN             NaN           4.803345e+05   \n1526665                      NaN             NaN           1.526365e+04   \n1526666                      NaN             NaN           4.999750e+05   \n1526667                      NaN             NaN                    NaN   \n1526668                      NaN             NaN           1.563078e+06   \n\n         dateofbirth_337D  days120_123L  days180_256L  ...  \\\n0                -16423.0           0.0           0.0  ...   \n1                -19126.0           1.0           3.0  ...   \n2                -14477.0           2.0           5.0  ...   \n3                 -9285.0           2.0           2.0  ...   \n4                -26469.0           0.0           0.0  ...   \n...                   ...           ...           ...  ...   \n1526664          -12999.0           0.0           0.0  ...   \n1526665          -16281.0           2.0           2.0  ...   \n1526666          -19767.0           1.0           2.0  ...   \n1526667          -26408.0           4.0           4.0  ...   \n1526668          -22723.0           6.0           9.0  ...   \n\n         pmts_dpd_303P_MEAN  pmts_overdue_1140A_MEAN  pmts_overdue_1152A_MEAN  \\\n0                       NaN              5714.283203                      NaN   \n1                 17.328571              6954.425293               858.877136   \n2                  1.777778               319.399994               630.443542   \n3                  0.076923                 0.000000                44.184616   \n4                       NaN                 0.000000                      NaN   \n...                     ...                      ...                      ...   \n1526664            0.000000                 0.000000                 0.000000   \n1526665                 NaN                      NaN                      NaN   \n1526666            0.000000                 0.000000                 0.000000   \n1526667         2328.571533                      NaN             33346.402344   \n1526668                 NaN                      NaN                      NaN   \n\n        pmts_dpd_1073P_VAR pmts_dpd_303P_VAR pmts_overdue_1140A_VAR  \\\n0             2.403380e+02               NaN           1.125995e+08   \n1             3.048952e+06       2296.774414           9.177756e+07   \n2             1.672040e+01         22.197254           1.040736e+06   \n3             0.000000e+00          0.076923           0.000000e+00   \n4             0.000000e+00               NaN           0.000000e+00   \n...                    ...               ...                    ...   \n1526664       0.000000e+00          0.000000           0.000000e+00   \n1526665                NaN               NaN                    NaN   \n1526666                NaN               NaN                    NaN   \n1526667                NaN       3341.619141                    NaN   \n1526668                NaN               NaN                    NaN   \n\n         pmts_overdue_1152A_VAR  year day partition  \n0                           NaN  2019  16     train  \n1                  2.149396e+06  2020  13     train  \n2                  1.885690e+06  2020  21     train  \n3                  2.537964e+04  2019   2     train  \n4                           NaN  2019  19     train  \n...                         ...   ...  ..       ...  \n1526664            0.000000e+00  2022   4      test  \n1526665                     NaN  2021  27      test  \n1526666                     NaN  2021  16      test  \n1526667            0.000000e+00  2021  20      test  \n1526668                     NaN  2022  17      test  \n\n[1526669 rows x 472 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>case_id</th>\n      <th>week_num</th>\n      <th>target</th>\n      <th>assignmentdate_238D</th>\n      <th>assignmentdate_4527235D</th>\n      <th>birthdate_574D</th>\n      <th>contractssum_5085716L</th>\n      <th>dateofbirth_337D</th>\n      <th>days120_123L</th>\n      <th>days180_256L</th>\n      <th>...</th>\n      <th>pmts_dpd_303P_MEAN</th>\n      <th>pmts_overdue_1140A_MEAN</th>\n      <th>pmts_overdue_1152A_MEAN</th>\n      <th>pmts_dpd_1073P_VAR</th>\n      <th>pmts_dpd_303P_VAR</th>\n      <th>pmts_overdue_1140A_VAR</th>\n      <th>pmts_overdue_1152A_VAR</th>\n      <th>year</th>\n      <th>day</th>\n      <th>partition</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>633272</td>\n      <td>6</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-16423.0</td>\n      <td>NaN</td>\n      <td>-16423.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>5714.283203</td>\n      <td>NaN</td>\n      <td>2.403380e+02</td>\n      <td>NaN</td>\n      <td>1.125995e+08</td>\n      <td>NaN</td>\n      <td>2019</td>\n      <td>16</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1839502</td>\n      <td>71</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-19126.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>17.328571</td>\n      <td>6954.425293</td>\n      <td>858.877136</td>\n      <td>3.048952e+06</td>\n      <td>2296.774414</td>\n      <td>9.177756e+07</td>\n      <td>2.149396e+06</td>\n      <td>2020</td>\n      <td>13</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>238999</td>\n      <td>81</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.962562e+05</td>\n      <td>-14477.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>1.777778</td>\n      <td>319.399994</td>\n      <td>630.443542</td>\n      <td>1.672040e+01</td>\n      <td>22.197254</td>\n      <td>1.040736e+06</td>\n      <td>1.885690e+06</td>\n      <td>2020</td>\n      <td>21</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1663056</td>\n      <td>47</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-9285.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.076923</td>\n      <td>0.000000</td>\n      <td>44.184616</td>\n      <td>0.000000e+00</td>\n      <td>0.076923</td>\n      <td>0.000000e+00</td>\n      <td>2.537964e+04</td>\n      <td>2019</td>\n      <td>2</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2544202</td>\n      <td>7</td>\n      <td>0</td>\n      <td>-5026.0</td>\n      <td>NaN</td>\n      <td>-26469.0</td>\n      <td>NaN</td>\n      <td>-26469.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>0.000000e+00</td>\n      <td>NaN</td>\n      <td>0.000000e+00</td>\n      <td>NaN</td>\n      <td>2019</td>\n      <td>19</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1526664</th>\n      <td>57631</td>\n      <td>100</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.803345e+05</td>\n      <td>-12999.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>2022</td>\n      <td>4</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>1526665</th>\n      <td>57634</td>\n      <td>100</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.526365e+04</td>\n      <td>-16281.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2021</td>\n      <td>27</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>1526666</th>\n      <td>57630</td>\n      <td>100</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.999750e+05</td>\n      <td>-19767.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2021</td>\n      <td>16</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>1526667</th>\n      <td>57569</td>\n      <td>100</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-26408.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>2328.571533</td>\n      <td>NaN</td>\n      <td>33346.402344</td>\n      <td>NaN</td>\n      <td>3341.619141</td>\n      <td>NaN</td>\n      <td>0.000000e+00</td>\n      <td>2021</td>\n      <td>20</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>1526668</th>\n      <td>57549</td>\n      <td>100</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.563078e+06</td>\n      <td>-22723.0</td>\n      <td>6.0</td>\n      <td>9.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2022</td>\n      <td>17</td>\n      <td>test</td>\n    </tr>\n  </tbody>\n</table>\n<p>1526669 rows × 472 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"features = df.columns[3:-1].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-05-21T01:43:10.164894Z","iopub.execute_input":"2024-05-21T01:43:10.165369Z","iopub.status.idle":"2024-05-21T01:43:10.171387Z","shell.execute_reply.started":"2024-05-21T01:43:10.165334Z","shell.execute_reply":"2024-05-21T01:43:10.170158Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"numeric_cols = [x for x in features if x not in cat_cols]","metadata":{"execution":{"iopub.status.busy":"2024-05-21T01:43:10.547033Z","iopub.execute_input":"2024-05-21T01:43:10.548109Z","iopub.status.idle":"2024-05-21T01:43:10.553793Z","shell.execute_reply.started":"2024-05-21T01:43:10.548070Z","shell.execute_reply":"2024-05-21T01:43:10.552417Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# uncorrelate features \nnans_df = df.loc[df['partition']=='train',numeric_cols].isna()\nnans_groups = {}\nfor col in numeric_cols:\n    cur_group = nans_df[col].sum()\n    if cur_group in nans_groups:\n        nans_groups[cur_group].append(col)\n    else:\n        nans_groups[cur_group]=[col]\ndel nans_df\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-05-21T01:43:11.219838Z","iopub.execute_input":"2024-05-21T01:43:11.220346Z","iopub.status.idle":"2024-05-21T01:43:17.436819Z","shell.execute_reply.started":"2024-05-21T01:43:11.220307Z","shell.execute_reply":"2024-05-21T01:43:17.435044Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"uncorrelated_feats = []\nfor k,v in tqdm(nans_groups.items()):\n    if len(v)>1:\n            vals = nans_groups[k]\n            grps = group_columns_by_correlation(df.loc[df['partition']=='train',numeric_cols], threshold=0.8)\n            use  = reduce_group(grps)\n            uncorrelated_feats.extend(use)\n    else:\n        uncorrelated_feats.extend(v)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T01:44:45.121117Z","iopub.execute_input":"2024-05-21T01:44:45.121680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = uncorrelated_feats + cat_cols\ndf = df[['case_id','target','partition'] + features]\ndf.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# exploration","metadata":{}},{"cell_type":"code","source":"# placeholder for exploration code ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# training","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split,StratifiedGroupKFold\nimport lightgbm as lgb \nfrom hyperopt import fmin, tpe, hp, SparkTrials, STATUS_OK\nfrom hyperopt.pyll import scope\nfrom functools import partial","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gini_stability(base, w_fallingrate=88.0, w_resstd=-0.5):\n    gini_in_time = base.loc[:, [\"WEEK_NUM\", \"target\", \"score\"]]\\\n        .sort_values(\"WEEK_NUM\")\\\n        .groupby(\"WEEK_NUM\")[[\"target\", \"score\"]]\\\n        .apply(lambda x: 2*roc_auc_score(x[\"target\"], x[\"score\"])-1).tolist()\n    \n    x = np.arange(len(gini_in_time))\n    y = gini_in_time\n    a, b = np.polyfit(x, y, 1)\n    y_hat = a*x + b\n    residuals = y - y_hat\n    res_std = np.std(residuals)\n    avg_gini = np.mean(gini_in_time)\n    return avg_gini + w_fallingrate * min(0, a) + w_resstd * res_std","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_base_params():\n    base_params = {\n        'boosting_type':'gbdt',\n        'random_state': 117,\n        'objective': 'binary',\n        'metric': 'auc',\n        'extra_trees':True,\n        'verbose': -1,\n        'max_bin': 200,\n#         'device_type': 'gpu',\n#         'gpu_use_dp': True,\n        \n    }\n    return base_params","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set up search space\nsearch_space_setup = {\n    'feature_fraction': hp.uniform('feature_fraction', 0.3, .9),\n    'bagging_fraction': hp.uniform('bagging_fraction', 0.3, .9),\n    'lambda_l1': hp.loguniform('lambda_l1', np.log(.000001), np.log(1000)),\n    'lambda_l2': hp.loguniform('lambda_l2', np.log(.000001), np.log(1000)),\n    'bagging_freq': scope.int(hp.uniform('bagging_freq', 2, 10)),\n    'min_data_in_leaf': scope.int(hp.uniform('min_data_in_leaf', 100, 10000)),\n    'learning_rate' : hp.uniform('learning_rate', 0.001, .1),\n    'num_leaves': scope.int(hp.uniform('num_leaves', 20, 5000)),\n    'min_gain_to_split': hp.uniform('min_gain_to_split', 0, 15),\n}\nsearch_space = get_base_params()\nfor k,v in search_space_setup.items():\n    search_space[k] = v","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def trial_fn_lgbm_auc(params,splits = None):\n    \n    scores = []\n    for train_idx, valid_idx in splits:\n        model = lgb.LGBMClassifier(**params)  \n        model.fit(df.loc[train_idx,features], df.loc[train_idx,'target'],\n                  eval_set=[(df_train.loc[valid_idx,features], df_train.loc[valid_idx,'target'])],\n                  eval_metric='auc',\n                  callbacks=[lgb.early_stopping(50)])\n\n        score = roc_auc_score(df_train.loc[valid_idx,'target'],model.predict_proba(df_train.loc[valid_idx,features]))\n        scores.append(score)\n    \n    score = np.mean(scores) - np.std(scores)\n    out = {\"status\": STATUS_OK, \"loss\": -score} # always minimizes\n    return out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbtrain = lgb.Dataset(df_train[features], label=df_train['target'])\ntest_X   = df_test[features].copy()\nsubmission = df_test[['case_id']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# do splits ahead of time to improve trial speed\nk = 5\nsplits   = [(train_idx,valid_idx) for train_idx,valid_idx in \n          StratifiedGroupKFold(n_splits=k).split(np.arange(df_train.shape[0]),\n                                                 df_train['target'],\n                                                 groups = df_train['week_num'])]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df_test\ndel df_train\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_params = fmin(fn=partial(trial_fn, splits = splits, dataset = lgbtrain),\n                    space=search_space,\n                    algo=tpe.suggest,\n                    max_evals=100,\n                    timeout=60*60*6 # seconds\n                  )\nint_params = ['max_depth','n_estimators','bagging_freq','num_leaves']\nbestp = get_base_params()\nfor k,v in best_params.items():\n    if k in int_params:\n        bestp[k] = int(v)\n    else:\n        bestp[k] = v\nbestp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# bestp = {\n#          'boosting_type': 'gbdt',\n# #          'device_type': 'gpu',\n#          'random_state': 117,\n#          'objective': 'binary',\n#          'metric': 'auc',\n#          'extra_trees': True,\n#          'verbose': -1,\n#          'max_bin': 64,\n#          'bagging_fraction': 0.6615111203742043,\n#          'bagging_freq': 4,\n#          'cat_l2': 0.4303012850161522,\n#          'colsample_bynode': 0.30799275380454566,\n#          'l1_regularization': 0.09818609605701412,\n#          'l2_regularization': 45.88388390697673,\n#          'learning_rate': 0.06583892942324936,\n#          'max_depth': 15,\n#          'n_estimators': 849,\n#          'num_leaves': 100,\n#          'verbose': 1\n#         }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gbm = lgb.train(\n    bestp,\n    lgbtrain,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# submission","metadata":{}},{"cell_type":"code","source":"submission['score'] = gbm.predict(test_X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)\nsubmission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}