{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":50160,"databundleVersionId":7921029,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport polars as pl\nimport os, gc, warnings\nfrom glob import glob\nfrom pathlib import Path\nfrom typing import Any\n\nwarnings.filterwarnings(\"ignore\")\n\nROOT = Path(\"/kaggle/input/home-credit-credit-risk-model-stability\")\nTRAIN_DIR = ROOT / \"parquet_files\" / \"train\"\nTEST_DIR = ROOT / \"parquet_files\" / \"test\"","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:45:20.253801Z","iopub.execute_input":"2024-05-17T20:45:20.254261Z","iopub.status.idle":"2024-05-17T20:45:20.262286Z","shell.execute_reply.started":"2024-05-17T20:45:20.254227Z","shell.execute_reply":"2024-05-17T20:45:20.261093Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# preprocessing","metadata":{}},{"cell_type":"code","source":"class Utility:\n    @staticmethod\n    def get_feat_defs(ending_with: str) -> None:\n        \"\"\"\n        Retrieves feature definitions from a CSV file based on the specified ending.\n\n        Args:\n        - ending_with (str): Ending to filter feature definitions.\n\n        Returns:\n        - pl.DataFrame: Filtered feature definitions.\n        \"\"\"\n        feat_defs: pl.DataFrame = pl.read_csv(ROOT / \"feature_definitions.csv\")\n\n        filtered_feats: pl.DataFrame = feat_defs.filter(\n            pl.col(\"Variable\").apply(lambda var: var.endswith(ending_with))\n        )\n\n        with pl.Config(fmt_str_lengths=200, tbl_rows=-1):\n            print(filtered_feats)\n\n        filtered_feats = None\n        feat_defs = None\n\n    @staticmethod\n    def find_index(lst: list[Any], item: Any) -> int | None:\n        \"\"\"\n        Finds the index of an item in a list.\n\n        Args:\n        - lst (list): List to search.\n        - item (Any): Item to find in the list.\n\n        Returns:\n        - int | None: Index of the item if found, otherwise None.\n        \"\"\"\n        try:\n            return lst.index(item)\n        except ValueError:\n            return None\n\n    @staticmethod\n    def dtype_to_str(dtype: pl.DataType) -> str:\n        \"\"\"\n        Converts Polars data type to string representation.\n\n        Args:\n        - dtype (pl.DataType): Polars data type.\n\n        Returns:\n        - str: String representation of the data type.\n        \"\"\"\n        dtype_map = {\n            pl.Decimal: \"Decimal\",\n            pl.Float32: \"Float32\",\n            pl.Float64: \"Float64\",\n            pl.UInt8: \"UInt8\",\n            pl.UInt16: \"UInt16\",\n            pl.UInt32: \"UInt32\",\n            pl.UInt64: \"UInt64\",\n            pl.Int8: \"Int8\",\n            pl.Int16: \"Int16\",\n            pl.Int32: \"Int32\",\n            pl.Int64: \"Int64\",\n            pl.Date: \"Date\",\n            pl.Datetime: \"Datetime\",\n            pl.Duration: \"Duration\",\n            pl.Time: \"Time\",\n            pl.Array: \"Array\",\n            pl.List: \"List\",\n            pl.Struct: \"Struct\",\n            pl.String: \"String\",\n            pl.Categorical: \"Categorical\",\n            pl.Enum: \"Enum\",\n            pl.Utf8: \"Utf8\",\n            pl.Binary: \"Binary\",\n            pl.Boolean: \"Boolean\",\n            pl.Null: \"Null\",\n            pl.Object: \"Object\",\n            pl.Unknown: \"Unknown\",\n        }\n\n        return dtype_map.get(dtype)\n\n    @staticmethod\n    def find_feat_occur(regex_path: str, ending_with: str) -> pl.DataFrame:\n        \"\"\"\n        Finds occurrences of features ending with a specific string in Parquet files.\n\n        Args:\n        - regex_path (str): Regular expression to match Parquet file paths.\n        - ending_with (str): Ending to filter feature names.\n\n        Returns:\n        - pl.DataFrame: DataFrame containing feature definitions, data types, and file locations.\n        \"\"\"\n        feat_defs: pl.DataFrame = pl.read_csv(ROOT / \"feature_definitions.csv\").filter(\n            pl.col(\"Variable\").apply(lambda var: var.endswith(ending_with))\n        )\n        feat_defs.sort(by=[\"Variable\"])\n\n        feats: list[pl.String] = feat_defs[\"Variable\"].to_list()\n        feats.sort()\n\n        occurrences: list[list] = [[set(), set()] for _ in range(feat_defs.height)]\n\n        for path in glob(str(regex_path)):\n            df_schema: dict = pl.read_parquet_schema(path)\n\n            for feat, dtype in df_schema.items():\n                index: int = Utility.find_index(feats, feat)\n                if index != None:\n                    occurrences[index][0].add(Utility.dtype_to_str(dtype))\n                    occurrences[index][1].add(Path(path).stem)\n\n        data_types: list[str] = [None] * feat_defs.height\n        file_locs: list[str] = [None] * feat_defs.height\n\n        for i, feat in enumerate(feats):\n            data_types[i] = list(occurrences[i][0])\n            file_locs[i] = list(occurrences[i][1])\n\n        feat_defs = feat_defs.with_columns(pl.Series(data_types).alias(\"Data_Type(s)\"))\n        feat_defs = feat_defs.with_columns(pl.Series(file_locs).alias(\"File_Loc(s)\"))\n\n        return feat_defs\n\n    def reduce_memory_usage(df: pl.DataFrame, name) -> pl.DataFrame:\n        \"\"\"\n        Reduces memory usage of a DataFrame by converting column types.\n\n        Args:\n        - df (pl.DataFrame): DataFrame to optimize.\n        - name (str): Name of the DataFrame.\n\n        Returns:\n        - pl.DataFrame: Optimized DataFrame.\n        \"\"\"\n        print(\n            f\"Memory usage of dataframe \\\"{name}\\\" is {round(df.estimated_size('mb'), 4)} MB.\"\n        )\n\n        int_types = [\n            pl.Int8,\n            pl.Int16,\n            pl.Int32,\n            pl.Int64,\n            pl.UInt8,\n            pl.UInt16,\n            pl.UInt32,\n            pl.UInt64,\n        ]\n        float_types = [pl.Float32, pl.Float64]\n\n        for col in df.columns:\n            col_type = df[col].dtype\n            if col_type in int_types + float_types:\n                c_min = df[col].min()\n                c_max = df[col].max()\n\n                if c_min is not None and c_max is not None:\n                    if col_type in int_types:\n                        if c_min >= 0:\n                            if (\n                                c_min >= np.iinfo(np.uint8).min\n                                and c_max <= np.iinfo(np.uint8).max\n                            ):\n                                df = df.with_columns(df[col].cast(pl.UInt8))\n                            elif (\n                                c_min >= np.iinfo(np.uint16).min\n                                and c_max <= np.iinfo(np.uint16).max\n                            ):\n                                df = df.with_columns(df[col].cast(pl.UInt16))\n                            elif (\n                                c_min >= np.iinfo(np.uint32).min\n                                and c_max <= np.iinfo(np.uint32).max\n                            ):\n                                df = df.with_columns(df[col].cast(pl.UInt32))\n                            elif (\n                                c_min >= np.iinfo(np.uint64).min\n                                and c_max <= np.iinfo(np.uint64).max\n                            ):\n                                df = df.with_columns(df[col].cast(pl.UInt64))\n                        else:\n                            if (\n                                c_min >= np.iinfo(np.int8).min\n                                and c_max <= np.iinfo(np.int8).max\n                            ):\n                                df = df.with_columns(df[col].cast(pl.Int8))\n                            elif (\n                                c_min >= np.iinfo(np.int16).min\n                                and c_max <= np.iinfo(np.int16).max\n                            ):\n                                df = df.with_columns(df[col].cast(pl.Int16))\n                            elif (\n                                c_min >= np.iinfo(np.int32).min\n                                and c_max <= np.iinfo(np.int32).max\n                            ):\n                                df = df.with_columns(df[col].cast(pl.Int32))\n                            elif (\n                                c_min >= np.iinfo(np.int64).min\n                                and c_max <= np.iinfo(np.int64).max\n                            ):\n                                df = df.with_columns(df[col].cast(pl.Int64))\n                    elif col_type in float_types:\n                        if (\n                            c_min > np.finfo(np.float32).min\n                            and c_max < np.finfo(np.float32).max\n                        ):\n                            df = df.with_columns(df[col].cast(pl.Float32))\n\n        print(\n            f\"Memory usage of dataframe \\\"{name}\\\" became {round(df.estimated_size('mb'), 4)} MB.\"\n        )\n\n        return df\n\n    def to_pandas(df: pl.DataFrame, cat_cols: list[str] = None) -> (pd.DataFrame, list[str]):  # type: ignore\n        \"\"\"\n        Converts a Polars DataFrame to a Pandas DataFrame.\n\n        Args:\n        - df (pl.DataFrame): Polars DataFrame to convert.\n        - cat_cols (list[str]): List of categorical columns. Default is None.\n\n        Returns:\n        - (pd.DataFrame, list[str]): Tuple containing the converted Pandas DataFrame and categorical columns.\n        \"\"\"\n        df: pd.DataFrame = df.to_pandas()\n\n        if cat_cols is None:\n            cat_cols = list(df.select_dtypes(\"object\").columns)\n\n        df[cat_cols] = df[cat_cols].astype(\"category\")\n\n        return df, cat_cols","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:45:20.264961Z","iopub.execute_input":"2024-05-17T20:45:20.265639Z","iopub.status.idle":"2024-05-17T20:45:20.309556Z","shell.execute_reply.started":"2024-05-17T20:45:20.265596Z","shell.execute_reply":"2024-05-17T20:45:20.308265Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class Aggregator:\n    @staticmethod\n    def max_expr(df: pl.LazyFrame) -> list[pl.Series]:\n        \"\"\"\n        Generates expressions for calculating maximum values for specific columns.\n\n        Args:\n        - df (pl.LazyFrame): Input LazyFrame.\n\n        Returns:\n        - list[pl.Series]: List of expressions for maximum values.\n        \"\"\"\n        cols: list[str] = [\n            col\n            for col in df.columns\n            if (col[-1] in (\"P\", \"M\", \"A\", \"D\", \"T\", \"L\")) or (\"num_group\" in col)\n        ]\n\n        expr_max: list[pl.Series] = [\n            pl.col(col).max().alias(f\"{col}_MAX\") for col in cols\n        ]\n\n        return expr_max\n\n    @staticmethod\n    def min_expr(df: pl.LazyFrame) -> list[pl.Series]:\n        \"\"\"\n        Generates expressions for calculating minimum values for specific columns.\n\n        Args:\n        - df (pl.LazyFrame): Input LazyFrame.\n\n        Returns:\n        - list[pl.Series]: List of expressions for minimum values.\n        \"\"\"\n        cols: list[str] = [\n            col\n            for col in df.columns\n            if (col[-1] in (\"P\", \"M\", \"A\", \"D\", \"T\", \"L\")) or (\"num_group\" in col)\n        ]\n\n        expr_min: list[pl.Series] = [\n            pl.col(col).min().alias(f\"{col}_MIN\") for col in cols\n        ]\n\n        return expr_min\n\n    @staticmethod\n    def mean_expr(df: pl.LazyFrame) -> list[pl.Series]:\n        \"\"\"\n        Generates expressions for calculating mean values for specific columns.\n\n        Args:\n        - df (pl.LazyFrame): Input LazyFrame.\n\n        Returns:\n        - list[pl.Series]: List of expressions for mean values.\n        \"\"\"\n        cols: list[str] = [col for col in df.columns if col.endswith((\"P\", \"A\", \"D\"))]\n\n        expr_mean: list[pl.Series] = [\n            pl.col(col).mean().alias(f\"{col}_MEAN\") for col in cols\n        ]\n\n        return expr_mean\n\n    @staticmethod\n    def var_expr(df: pl.LazyFrame) -> list[pl.Series]:\n        \"\"\"\n        Generates expressions for calculating variance for specific columns.\n\n        Args:\n        - df (pl.LazyFrame): Input LazyFrame.\n\n        Returns:\n        - list[pl.Series]: List of expressions for variance.\n        \"\"\"\n        cols: list[str] = [col for col in df.columns if col.endswith((\"P\", \"A\", \"D\"))]\n\n        expr_mean: list[pl.Series] = [\n            pl.col(col).var().alias(f\"{col}_VAR\") for col in cols\n        ]\n\n        return expr_mean\n\n    @staticmethod\n    def mode_expr(df: pl.LazyFrame) -> list[pl.Series]:\n        \"\"\"\n        Generates expressions for calculating mode values for specific columns.\n\n        Args:\n        - df (pl.LazyFrame): Input LazyFrame.\n\n        Returns:\n        - list[pl.Series]: List of expressions for mode values.\n        \"\"\"\n        cols: list[str] = [col for col in df.columns if col.endswith(\"M\")]\n\n        expr_mode: list[pl.Series] = [\n            pl.col(col).drop_nulls().mode().first().alias(f\"{col}_MODE\") for col in cols\n        ]\n\n        return expr_mode\n\n    @staticmethod\n    def get_exprs(df: pl.LazyFrame) -> list[pl.Series]:\n        \"\"\"\n        Combines expressions for maximum, mean, and variance calculations.\n\n        Args:\n        - df (pl.LazyFrame): Input LazyFrame.\n\n        Returns:\n        - list[pl.Series]: List of combined expressions.\n        \"\"\"\n        exprs = (\n            Aggregator.max_expr(df) + Aggregator.mean_expr(df) + Aggregator.var_expr(df)\n        )\n\n        return exprs","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:45:20.320087Z","iopub.execute_input":"2024-05-17T20:45:20.320491Z","iopub.status.idle":"2024-05-17T20:45:20.344907Z","shell.execute_reply.started":"2024-05-17T20:45:20.320457Z","shell.execute_reply":"2024-05-17T20:45:20.343651Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class SchemaGen:\n    @staticmethod\n    def change_dtypes(df: pl.LazyFrame) -> pl.LazyFrame:\n        \"\"\"\n        Changes the data types of columns in the DataFrame.\n\n        Args:\n        - df (pl.LazyFrame): Input LazyFrame.\n\n        Returns:\n        - pl.LazyFrame: LazyFrame with modified data types.\n        \"\"\"\n        for col in df.columns:\n            if col == \"case_id\":\n                df = df.with_columns(pl.col(col).cast(pl.UInt32).alias(col))\n            elif col in [\"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n                df = df.with_columns(pl.col(col).cast(pl.UInt16).alias(col))\n            elif col == \"date_decision\" or col[-1] == \"D\":\n                df = df.with_columns(pl.col(col).cast(pl.Date).alias(col))\n            elif col[-1] in [\"P\", \"A\"]:\n                df = df.with_columns(pl.col(col).cast(pl.Float64).alias(col))\n            elif col[-1] in (\"M\",):\n                df = df.with_columns(pl.col(col).cast(pl.String))\n        return df\n\n    @staticmethod\n    def scan_files(glob_path: str, depth: int = None):\n        chunks = []\n        for path in glob(str(glob_path)):\n            df = pl.read_parquet(path, low_memory=True, rechunk=True)\n            df = df.pipe(SchemaGen.change_dtypes)\n            if depth in [1, 2]:\n                df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n            chunks.append(df)\n        df = pl.concat(chunks, how=\"vertical_relaxed\")\n        del chunks\n        gc.collect()\n\n        df = df.unique(subset=[\"case_id\"]) \n        \n        return df\n\n    @staticmethod\n    def join_dataframes(df_base, depth_0, depth_1, depth_2):\n        for i, df in enumerate(depth_0 + depth_1 + depth_2):\n            df_base = df_base.join(df, how=\"left\", on=\"case_id\", suffix=f\"_{i}\")\n        return df_base\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:45:20.347658Z","iopub.execute_input":"2024-05-17T20:45:20.348188Z","iopub.status.idle":"2024-05-17T20:45:20.364790Z","shell.execute_reply.started":"2024-05-17T20:45:20.348144Z","shell.execute_reply":"2024-05-17T20:45:20.363356Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def filter_cols(df: pl.DataFrame) -> pl.DataFrame:\n    \"\"\"\n    Filters columns in the DataFrame based on null percentage and unique values for string columns.\n\n    Args:\n    - df (pl.DataFrame): Input DataFrame.\n\n    Returns:\n    - pl.DataFrame: DataFrame with filtered columns.\n    \"\"\"\n    for col in df.columns:\n        if col not in [\"case_id\", \"year\", \"month\", \"week_num\", \"target\"]:\n            null_pct = df[col].is_null().mean()\n\n            if null_pct > 0.95:\n                df = df.drop(col)\n\n    for col in df.columns:\n        if (col not in [\"case_id\", \"year\", \"month\", \"week_num\", \"target\"]) & (\n            df[col].dtype == pl.String\n        ):\n            freq = df[col].n_unique()\n\n            if (freq > 200) | (freq == 1):\n                df = df.drop(col)\n\n    return df\n\n\ndef transform_cols(df: pl.DataFrame) -> pl.DataFrame:\n    \"\"\"\n    Transforms columns in the DataFrame according to predefined rules.\n\n    Args:\n    - df (pl.DataFrame): Input DataFrame.\n\n    Returns:\n    - pl.DataFrame: DataFrame with transformed columns.\n    \"\"\"\n    if \"riskassesment_302T\" in df.columns:\n        if df[\"riskassesment_302T\"].dtype == pl.Null:\n            df = df.with_columns(\n                [\n                    pl.Series(\n                        \"riskassesment_302T_rng\", df[\"riskassesment_302T\"], pl.UInt8\n                    ),\n                    pl.Series(\n                        \"riskassesment_302T_mean\", df[\"riskassesment_302T\"], pl.UInt8\n                    ),\n                ]\n            )\n        else:\n            pct_low: pl.Series = (\n                df[\"riskassesment_302T\"]\n                .str.split(\" - \")\n                .apply(lambda x: x[0].replace(\"%\", \"\"))\n                .cast(pl.UInt8)\n            )\n            pct_high: pl.Series = (\n                df[\"riskassesment_302T\"]\n                .str.split(\" - \")\n                .apply(lambda x: x[1].replace(\"%\", \"\"))\n                .cast(pl.UInt8)\n            )\n\n            diff: pl.Series = pct_high - pct_low\n            avg: pl.Series = ((pct_low + pct_high) / 2).cast(pl.Float32)\n\n            del pct_high, pct_low\n            gc.collect()\n\n            df = df.with_columns(\n                [\n                    diff.alias(\"riskassesment_302T_rng\"),\n                    avg.alias(\"riskassesment_302T_mean\"),\n                ]\n            )\n\n        df.drop(\"riskassesment_302T\")\n\n    return df\n\n\ndef handle_dates(df: pl.DataFrame) -> pl.DataFrame:\n    \"\"\"\n    Handles date columns in the DataFrame.\n\n    Args:\n    - df (pl.DataFrame): Input DataFrame.\n\n    Returns:\n    - pl.DataFrame: DataFrame with transformed date columns.\n    \"\"\"\n    for col in df.columns:\n        if (col[-1] == 'D') or ('D_' in col):\n            df = df.with_columns(pl.col(col) - pl.col(\"date_decision\"))\n            df = df.with_columns(pl.col(col).dt.total_days().cast(pl.Int32))\n\n            \n    df = df.drop(\"MONTH\")\n    df = df.drop(\"WEEK_NUM\")\n\n    df = df.with_columns(pl.col(\"date_decision\").dt.year().alias(\"year\").cast(pl.Int16))\n    df = df.with_columns(pl.col(\"date_decision\").dt.month().alias(\"month\").cast(pl.Int16))\n    df = df.with_columns(pl.col(\"date_decision\").dt.day().alias(\"day\").cast(pl.UInt8))\n    df = df.with_columns(pl.col(\"date_decision\").dt.weekday().alias(\"weekday\").cast(pl.UInt8))\n    df = df.with_columns(((pl.col(\"date_decision\") - pl.lit(\"2019-01-01\").cast(pl.Date)).dt.total_days() / 7).floor().alias(\"week_num\").cast(pl.Int32))\n\n#     df = df.drop(\"date_decision\")\n    return df ","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:45:20.366499Z","iopub.execute_input":"2024-05-17T20:45:20.366929Z","iopub.status.idle":"2024-05-17T20:45:20.390074Z","shell.execute_reply.started":"2024-05-17T20:45:20.366824Z","shell.execute_reply":"2024-05-17T20:45:20.388704Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data_store: dict = {\n    \"df_base\": SchemaGen.scan_files(TRAIN_DIR / \"train_base.parquet\"),\n    \"depth_0\": [\n        SchemaGen.scan_files(TRAIN_DIR / \"train_static_cb_0.parquet\"),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_static_0_*.parquet\"),\n    ],\n    \"depth_1\": [\n        SchemaGen.scan_files(TRAIN_DIR / \"train_applprev_1_*.parquet\", 1),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_tax_registry_a_1.parquet\", 1),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_tax_registry_b_1.parquet\", 1),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_tax_registry_c_1.parquet\", 1),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_credit_bureau_a_1_*.parquet\", 1),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_credit_bureau_b_1.parquet\", 1),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_other_1.parquet\", 1),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_person_1.parquet\", 1),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_deposit_1.parquet\", 1),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_debitcard_1.parquet\", 1),\n    ],\n    \"depth_2\": [\n        SchemaGen.scan_files(TRAIN_DIR / \"train_credit_bureau_a_2_*.parquet\", 2),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_credit_bureau_b_2.parquet\", 2),\n    ],\n}\n\ndf_train: pl.DataFrame = (\n    SchemaGen.join_dataframes(**data_store)\n    .pipe(filter_cols)\n    .pipe(transform_cols)\n    .pipe(handle_dates)\n    .pipe(Utility.reduce_memory_usage, \"df_train\")\n)\n\ndel data_store\ngc.collect()\n\nprint(f\"Train data shape: {df_train.shape}\")\ndisplay(df_train.head(10))","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:45:20.393143Z","iopub.execute_input":"2024-05-17T20:45:20.393678Z","iopub.status.idle":"2024-05-17T20:48:47.663218Z","shell.execute_reply.started":"2024-05-17T20:45:20.393643Z","shell.execute_reply":"2024-05-17T20:48:47.661914Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Memory usage of dataframe \"df_train\" is 4712.6755 MB.\nMemory usage of dataframe \"df_train\" became 2668.5421 MB.\nTrain data shape: (1526659, 474)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"shape: (10, 474)\n┌─────────┬───────────────┬────────┬─────────────────────┬───┬───────┬─────┬─────────┬──────────┐\n│ case_id ┆ date_decision ┆ target ┆ assignmentdate_238D ┆ … ┆ month ┆ day ┆ weekday ┆ week_num │\n│ ---     ┆ ---           ┆ ---    ┆ ---                 ┆   ┆ ---   ┆ --- ┆ ---     ┆ ---      │\n│ u32     ┆ date          ┆ u8     ┆ i16                 ┆   ┆ u8    ┆ u8  ┆ u8      ┆ u8       │\n╞═════════╪═══════════════╪════════╪═════════════════════╪═══╪═══════╪═════╪═════════╪══════════╡\n│ 1248871 ┆ 2019-01-11    ┆ 0      ┆ null                ┆ … ┆ 1     ┆ 11  ┆ 5       ┆ 1        │\n│ 2530977 ┆ 2019-01-08    ┆ 0      ┆ null                ┆ … ┆ 1     ┆ 8   ┆ 2       ┆ 1        │\n│ 608260  ┆ 2019-01-11    ┆ 0      ┆ null                ┆ … ┆ 1     ┆ 11  ┆ 5       ┆ 1        │\n│ 122337  ┆ 2019-04-12    ┆ 0      ┆ -9427               ┆ … ┆ 4     ┆ 12  ┆ 5       ┆ 14       │\n│ 111449  ┆ 2019-02-16    ┆ 0      ┆ null                ┆ … ┆ 2     ┆ 16  ┆ 6       ┆ 6        │\n│ 974252  ┆ 2020-03-19    ┆ 0      ┆ null                ┆ … ┆ 3     ┆ 19  ┆ 4       ┆ 63       │\n│ 694792  ┆ 2019-05-22    ┆ 0      ┆ null                ┆ … ┆ 5     ┆ 22  ┆ 3       ┆ 20       │\n│ 1924450 ┆ 2020-09-10    ┆ 0      ┆ null                ┆ … ┆ 9     ┆ 10  ┆ 4       ┆ 88       │\n│ 965103  ┆ 2020-02-28    ┆ 0      ┆ null                ┆ … ┆ 2     ┆ 28  ┆ 5       ┆ 60       │\n│ 1924861 ┆ 2020-09-10    ┆ 0      ┆ null                ┆ … ┆ 9     ┆ 10  ┆ 4       ┆ 88       │\n└─────────┴───────────────┴────────┴─────────────────────┴───┴───────┴─────┴─────────┴──────────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (10, 474)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>case_id</th><th>date_decision</th><th>target</th><th>assignmentdate_238D</th><th>assignmentdate_4527235D</th><th>birthdate_574D</th><th>contractssum_5085716L</th><th>dateofbirth_337D</th><th>days120_123L</th><th>days180_256L</th><th>days30_165L</th><th>days360_512L</th><th>days90_310L</th><th>description_5085714M</th><th>education_1103M</th><th>education_88M</th><th>firstquarter_103L</th><th>fourthquarter_440L</th><th>maritalst_385M</th><th>maritalst_893M</th><th>numberofqueries_373L</th><th>pmtaverage_3A</th><th>pmtaverage_4527227A</th><th>pmtcount_4527229L</th><th>pmtcount_693L</th><th>pmtscount_423L</th><th>pmtssum_45A</th><th>requesttype_4525192L</th><th>responsedate_1012D</th><th>responsedate_4527233D</th><th>responsedate_4917613D</th><th>secondquarter_766L</th><th>thirdquarter_1082L</th><th>actualdpdtolerance_344P</th><th>amtinstpaidbefduel24m_4187115A</th><th>annuity_780A</th><th>annuitynextmonth_57A</th><th>&hellip;</th><th>openingdate_313D_MAX</th><th>amount_416A_MEAN</th><th>openingdate_313D_MEAN</th><th>num_group1_MAX_11</th><th>openingdate_857D_MAX</th><th>openingdate_857D_MEAN</th><th>collater_typofvalofguarant_298M_MAX</th><th>collater_typofvalofguarant_407M_MAX</th><th>collater_valueofguarantee_1124L_MAX</th><th>collater_valueofguarantee_876L_MAX</th><th>collaterals_typeofguarante_359M_MAX</th><th>collaterals_typeofguarante_669M_MAX</th><th>num_group1_MAX_12</th><th>num_group2_MAX</th><th>pmts_dpd_1073P_MAX</th><th>pmts_dpd_303P_MAX</th><th>pmts_month_158T_MAX</th><th>pmts_month_706T_MAX</th><th>pmts_overdue_1140A_MAX</th><th>pmts_overdue_1152A_MAX</th><th>pmts_year_1139T_MAX</th><th>pmts_year_507T_MAX</th><th>subjectroles_name_541M_MAX</th><th>subjectroles_name_838M_MAX</th><th>pmts_dpd_1073P_MEAN</th><th>pmts_dpd_303P_MEAN</th><th>pmts_overdue_1140A_MEAN</th><th>pmts_overdue_1152A_MEAN</th><th>pmts_dpd_1073P_VAR</th><th>pmts_dpd_303P_VAR</th><th>pmts_overdue_1140A_VAR</th><th>pmts_overdue_1152A_VAR</th><th>year</th><th>month</th><th>day</th><th>weekday</th><th>week_num</th></tr><tr><td>u32</td><td>date</td><td>u8</td><td>i16</td><td>u8</td><td>i16</td><td>f32</td><td>i32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>str</td><td>str</td><td>str</td><td>f32</td><td>f32</td><td>str</td><td>str</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>str</td><td>i8</td><td>u8</td><td>i8</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>&hellip;</td><td>i16</td><td>f32</td><td>i16</td><td>u8</td><td>i16</td><td>i16</td><td>str</td><td>str</td><td>f32</td><td>f32</td><td>str</td><td>str</td><td>u16</td><td>u8</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>str</td><td>str</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>u16</td><td>u8</td><td>u8</td><td>u8</td><td>u8</td></tr></thead><tbody><tr><td>1248871</td><td>2019-01-11</td><td>0</td><td>null</td><td>null</td><td>-18852</td><td>null</td><td>-18852</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>3.0</td><td>0.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>1.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>6.0</td><td>2765.600098</td><td>null</td><td>14</td><td>null</td><td>null</td><td>0.0</td><td>1.0</td><td>0.0</td><td>null</td><td>3666.400146</td><td>6373.399902</td><td>&hellip;</td><td>-1077</td><td>0.0</td><td>-1077</td><td>0</td><td>-1077</td><td>-1077</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;c7a5ad39&quot;</td><td>0</td><td>23</td><td>0.0</td><td>null</td><td>12.0</td><td>null</td><td>0.0</td><td>null</td><td>2019.0</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>2019</td><td>1</td><td>11</td><td>5</td><td>1</td></tr><tr><td>2530977</td><td>2019-01-08</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>null</td><td>5999.399902</td><td>0.0</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>2019</td><td>1</td><td>8</td><td>2</td><td>1</td></tr><tr><td>608260</td><td>2019-01-11</td><td>0</td><td>null</td><td>null</td><td>-15747</td><td>null</td><td>-15747</td><td>0.0</td><td>2.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>0.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>2.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>6.0</td><td>3394.199951</td><td>null</td><td>14</td><td>null</td><td>null</td><td>3.0</td><td>4.0</td><td>null</td><td>null</td><td>1331.200073</td><td>0.0</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;c7a5ad39&quot;</td><td>0</td><td>23</td><td>0.0</td><td>null</td><td>12.0</td><td>null</td><td>0.0</td><td>null</td><td>2019.0</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>2019</td><td>1</td><td>11</td><td>5</td><td>1</td></tr><tr><td>122337</td><td>2019-04-12</td><td>0</td><td>-9427</td><td>null</td><td>-27070</td><td>null</td><td>-27070</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>&quot;a55475b1&quot;</td><td>&quot;c8e1a1d0&quot;</td><td>&quot;a55475b1&quot;</td><td>1.0</td><td>2.0</td><td>&quot;3439d993&quot;</td><td>&quot;a55475b1&quot;</td><td>1.0</td><td>9994.333984</td><td>null</td><td>null</td><td>6.0</td><td>null</td><td>null</td><td>null</td><td>14</td><td>null</td><td>null</td><td>0.0</td><td>1.0</td><td>0.0</td><td>187195.796875</td><td>4203.200195</td><td>9434.400391</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;c7a5ad39&quot;</td><td>1</td><td>35</td><td>20.0</td><td>null</td><td>12.0</td><td>null</td><td>4368.052246</td><td>null</td><td>2020.0</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.88</td><td>null</td><td>176.380173</td><td>null</td><td>16.026667</td><td>null</td><td>762660.375</td><td>null</td><td>2019</td><td>4</td><td>12</td><td>5</td><td>14</td></tr><tr><td>111449</td><td>2019-02-16</td><td>0</td><td>null</td><td>null</td><td>-11522</td><td>null</td><td>-11522</td><td>3.0</td><td>5.0</td><td>1.0</td><td>9.0</td><td>3.0</td><td>&quot;a55475b1&quot;</td><td>&quot;6b2ae0fa&quot;</td><td>&quot;a55475b1&quot;</td><td>8.0</td><td>7.0</td><td>&quot;3439d993&quot;</td><td>&quot;a55475b1&quot;</td><td>9.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>6.0</td><td>12000.0</td><td>null</td><td>-1</td><td>null</td><td>null</td><td>4.0</td><td>7.0</td><td>0.0</td><td>null</td><td>3654.0</td><td>0.0</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;c7a5ad39&quot;</td><td>2</td><td>35</td><td>0.0</td><td>null</td><td>12.0</td><td>null</td><td>0.0</td><td>null</td><td>2020.0</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>2019</td><td>2</td><td>16</td><td>6</td><td>6</td></tr><tr><td>974252</td><td>2020-03-19</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-12892</td><td>0.0</td><td>1.0</td><td>0.0</td><td>2.0</td><td>0.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>1.0</td><td>1.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>2.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;DEDUCTION_6&quot;</td><td>null</td><td>14</td><td>null</td><td>1.0</td><td>3.0</td><td>null</td><td>null</td><td>9871.600586</td><td>0.0</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;c7a5ad39&quot;</td><td>2</td><td>35</td><td>0.0</td><td>null</td><td>12.0</td><td>null</td><td>0.0</td><td>null</td><td>2021.0</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>2020</td><td>3</td><td>19</td><td>4</td><td>63</td></tr><tr><td>694792</td><td>2019-05-22</td><td>0</td><td>null</td><td>null</td><td>-9759</td><td>null</td><td>-9759</td><td>0.0</td><td>0.0</td><td>0.0</td><td>3.0</td><td>0.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>1.0</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>3.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.0</td><td>0.0</td><td>null</td><td>14</td><td>null</td><td>null</td><td>0.0</td><td>2.0</td><td>null</td><td>null</td><td>1179.800049</td><td>0.0</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>8.311e6</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0</td><td>23</td><td>0.0</td><td>null</td><td>12.0</td><td>null</td><td>0.0</td><td>null</td><td>2020.0</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>2019</td><td>5</td><td>22</td><td>3</td><td>20</td></tr><tr><td>1924450</td><td>2020-09-10</td><td>0</td><td>null</td><td>null</td><td>null</td><td>1e6</td><td>-21437</td><td>2.0</td><td>2.0</td><td>2.0</td><td>3.0</td><td>2.0</td><td>&quot;2fc785b2&quot;</td><td>&quot;717ddd49&quot;</td><td>&quot;a55475b1&quot;</td><td>4.0</td><td>3.0</td><td>&quot;b6cabe76&quot;</td><td>&quot;a55475b1&quot;</td><td>3.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0</td><td>2.0</td><td>3.0</td><td>0.0</td><td>0.0</td><td>6467.800293</td><td>11259.200195</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>5.131782e6</td><td>&quot;c7a5ad39&quot;</td><td>&quot;c7a5ad39&quot;</td><td>2</td><td>35</td><td>0.0</td><td>0.0</td><td>12.0</td><td>12.0</td><td>0.0</td><td>0.0</td><td>2021.0</td><td>2016.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2020</td><td>9</td><td>10</td><td>4</td><td>88</td></tr><tr><td>965103</td><td>2020-02-28</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>-10285</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&quot;a55475b1&quot;</td><td>&quot;6b2ae0fa&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>0.0</td><td>&quot;a7fcb6e5&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;DEDUCTION_6&quot;</td><td>null</td><td>14</td><td>null</td><td>3.0</td><td>0.0</td><td>null</td><td>null</td><td>6127.0</td><td>0.0</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>0.0</td><td>&quot;a55475b1&quot;</td><td>&quot;c7a5ad39&quot;</td><td>0</td><td>35</td><td>0.0</td><td>0.0</td><td>12.0</td><td>12.0</td><td>0.0</td><td>0.0</td><td>2021.0</td><td>2019.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2020</td><td>2</td><td>28</td><td>5</td><td>60</td></tr><tr><td>1924861</td><td>2020-09-10</td><td>0</td><td>null</td><td>null</td><td>null</td><td>316337.4375</td><td>-23385</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>0.0</td><td>&quot;2fc785b2&quot;</td><td>&quot;717ddd49&quot;</td><td>&quot;a55475b1&quot;</td><td>1.0</td><td>1.0</td><td>&quot;3439d993&quot;</td><td>&quot;a55475b1&quot;</td><td>1.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>14</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>3476.600098</td><td>0.0</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;a55475b1&quot;</td><td>&quot;a55475b1&quot;</td><td>0.0</td><td>0.0</td><td>&quot;c7a5ad39&quot;</td><td>&quot;c7a5ad39&quot;</td><td>1</td><td>35</td><td>1.0</td><td>2330.0</td><td>12.0</td><td>12.0</td><td>134.199997</td><td>4457.0</td><td>2021.0</td><td>2016.0</td><td>&quot;ab3c25cf&quot;</td><td>&quot;ab3c25cf&quot;</td><td>0.083333</td><td>1804.148193</td><td>11.183333</td><td>2212.0</td><td>0.083333</td><td>454130.375</td><td>1500.803345</td><td>855185.625</td><td>2020</td><td>9</td><td>10</td><td>4</td><td>88</td></tr></tbody></table></div>"},"metadata":{}}]},{"cell_type":"code","source":"data_store: dict = {\n    \"df_base\": SchemaGen.scan_files(TEST_DIR / \"test_base.parquet\"),\n    \"depth_0\": [\n        SchemaGen.scan_files(TEST_DIR / \"test_static_cb_0.parquet\"),\n        SchemaGen.scan_files(TEST_DIR / \"test_static_0_*.parquet\"),\n    ],\n    \"depth_1\": [\n        SchemaGen.scan_files(TEST_DIR / \"test_applprev_1_*.parquet\", 1),\n        SchemaGen.scan_files(TEST_DIR / \"test_tax_registry_a_1.parquet\", 1),\n        SchemaGen.scan_files(TEST_DIR / \"test_tax_registry_b_1.parquet\", 1),\n        SchemaGen.scan_files(TEST_DIR / \"test_tax_registry_c_1.parquet\", 1),\n        SchemaGen.scan_files(TEST_DIR / \"test_credit_bureau_a_1_*.parquet\", 1),\n        SchemaGen.scan_files(TEST_DIR / \"test_credit_bureau_b_1.parquet\", 1),\n        SchemaGen.scan_files(TEST_DIR / \"test_other_1.parquet\", 1),\n        SchemaGen.scan_files(TEST_DIR / \"test_person_1.parquet\", 1),\n        SchemaGen.scan_files(TEST_DIR / \"test_deposit_1.parquet\", 1),\n        SchemaGen.scan_files(TEST_DIR / \"test_debitcard_1.parquet\", 1),\n    ],\n    \"depth_2\": [\n        SchemaGen.scan_files(TEST_DIR / \"test_credit_bureau_a_2_*.parquet\", 2),\n        SchemaGen.scan_files(TEST_DIR / \"test_credit_bureau_b_2.parquet\", 2),\n    ],\n}\n\ndf_test: pl.DataFrame = (\n    SchemaGen.join_dataframes(**data_store)\n    .pipe(transform_cols)\n    .pipe(handle_dates)\n    .select([col for col in df_train.columns if col != \"target\"])\n    .pipe(Utility.reduce_memory_usage, \"df_test\")\n)\n\ndel data_store\ngc.collect()\n\nprint(f\"Test data shape: {df_test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:48:47.664577Z","iopub.execute_input":"2024-05-17T20:48:47.664925Z","iopub.status.idle":"2024-05-17T20:48:50.324166Z","shell.execute_reply.started":"2024-05-17T20:48:47.664894Z","shell.execute_reply":"2024-05-17T20:48:50.322905Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Memory usage of dataframe \"df_test\" is 0.0298 MB.\nMemory usage of dataframe \"df_test\" became 0.0173 MB.\nTest data shape: (10, 473)\n","output_type":"stream"}]},{"cell_type":"code","source":"if 'target' not in df_test.columns:\n    df_test = df_test.with_columns(pl.lit(0).alias('target').cast(pl.Int8))","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:48:50.325946Z","iopub.execute_input":"2024-05-17T20:48:50.326653Z","iopub.status.idle":"2024-05-17T20:48:50.335799Z","shell.execute_reply.started":"2024-05-17T20:48:50.326611Z","shell.execute_reply":"2024-05-17T20:48:50.334333Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df, cat_cols = Utility.to_pandas(\n                        pl.concat([\n                                 df_train.with_columns(pl.lit('train').alias('partition')),\n                                 df_test.select(df_train.columns).with_columns(pl.lit('test').alias('partition'))\n                                    ],how='vertical_relaxed')\n                                )","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:48:50.337389Z","iopub.execute_input":"2024-05-17T20:48:50.338161Z","iopub.status.idle":"2024-05-17T20:49:18.423943Z","shell.execute_reply.started":"2024-05-17T20:48:50.338119Z","shell.execute_reply":"2024-05-17T20:49:18.422589Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df_train = df[df['partition']=='train'].reset_index(drop=True)\ndf_test  = df[df['partition']=='test'].reset_index(drop=True)\nn_train = df_train.shape[0]\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:49:18.425403Z","iopub.execute_input":"2024-05-17T20:49:18.425752Z","iopub.status.idle":"2024-05-17T20:49:22.679350Z","shell.execute_reply.started":"2024-05-17T20:49:18.425721Z","shell.execute_reply":"2024-05-17T20:49:22.675754Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# features = df_train.columns[5:-2]","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:49:22.680971Z","iopub.execute_input":"2024-05-17T20:49:22.681426Z","iopub.status.idle":"2024-05-17T20:49:22.690410Z","shell.execute_reply.started":"2024-05-17T20:49:22.681379Z","shell.execute_reply":"2024-05-17T20:49:22.686694Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"features = ['maxdpdtolerance_577P_MEAN', 'pmts_dpd_1073P_MEAN', 'dateofcredstart_739D_MEAN', 'pmts_dpd_1073P_VAR', 'pmts_overdue_1140A_MEAN', 'dpdmax_139P_MEAN', 'avgdpdtolclosure24_3658938P', 'birth_259D_MEAN', 'dateofbirth_337D', 'birth_259D_MAX', 'pmtnum_254L', 'firstclxcampaign_1125D', 'dateofcredstart_739D_MAX', 'price_1097A', 'disbursedcredamount_1113A', 'credamount_770A', 'lastrejectcredamount_222A', 'maxdpdlast24m_143P', 'overdueamountmax2_14A_MEAN', 'annuity_780A', 'days360_512L', 'numberofoverdueinstlmax_1039L_MAX', 'days180_256L', 'pctinstlsallpaidlate4d_3546849L', 'days90_310L', 'avgdbddpdlast24m_3658932P', 'firstnonzeroinstldate_307D_MAX', 'employedfrom_700D_MEAN', 'maxdpdlast12m_727P', 'employedfrom_700D_MAX', 'pctinstlsallpaidlate6d_3546844L', 'totalamount_996A_MEAN', 'tenor_203L_MAX', 'numrejects9m_859L', 'maxdbddpdtollast12m_3658940P', 'credamount_590A_MEAN', 'pctinstlsallpaidearl3d_427L', 'residualamount_856A_MEAN', 'pctinstlsallpaidlate1d_3546856L', 'incometype_1044T_MAX', 'pctinstlsallpaidlat10d_839L', 'pmtnum_8L_MAX', 'maxdpdtolerance_577P_MAX', 'numberofoverdueinstlmaxdat_641D_MEAN', 'dateofcredend_289D_MEAN', 'numinstlswithoutdpd_562L', 'days120_123L', 'annuity_853A_MEAN', 'numberofoverdueinstlmaxdat_641D_MAX', 'lastrejectdate_50D', 'overdueamountmax_155A_MEAN', 'dateofcredend_289D_MAX', 'overdueamountmax2_14A_MAX', 'overdueamountmax2date_1142D_MAX', 'credamount_590A_VAR', 'numinstlsallpaid_934L', 'firstnonzeroinstldate_307D_MEAN', 'lastrejectreason_759M', 'credamount_590A_MAX', 'creationdate_885D_MAX', 'numberofqueries_373L', 'totalsettled_863A', 'creationdate_885D_MEAN', 'monthsannuity_845L', 'pmts_overdue_1140A_VAR', 'overdueamountmax_155A_MAX', 'maxdbddpdlast1m_3658939P', 'overdueamountmax2date_1142D_MEAN', 'amtinstpaidbefduel24m_4187115A', 'datefirstoffer_1144D', 'residualamount_856A_MAX', 'pmts_dpd_1073P_MAX', 'annuity_853A_MAX', 'monthlyinstlamount_332A_MAX', 'totalamount_996A_MAX', 'pmts_overdue_1140A_MAX', 'currdebt_94A_MEAN', 'monthlyinstlamount_332A_MEAN', 'dtlastpmtallstes_3545839D_MEAN', 'dpdmax_139P_MAX', 'lastapplicationdate_877D', 'monthlyinstlamount_332A_VAR', 'day', 'mainoccupationinc_437A_VAR', 'cntpmts24_3658933L', 'numberofcontrsvalue_358L_MAX', 'avgdbddpdlast3m_4187120P', 'maxdpdfrom6mto36m_3546853P', 'numinstpaidearly3d_3546850L', 'mainoccupationinc_384A_MAX', 'maxdpdtolerance_374P', 'mainoccupationinc_437A_MEAN', 'days30_165L', 'dpdmax_757P_MEAN', 'lastdelinqdate_224D', 'sex_738L_MAX', 'maxdpdlast9m_1059P', 'dtlastpmtallstes_3545839D_MAX', 'outstandingamount_362A_MEAN', 'mindbddpdlast24m_3658935P', 'mobilephncnt_593L', 'instlamount_768A_MEAN', 'outstandingdebt_522A_MEAN', 'maxannuity_159A', 'numberofoverdueinstlmaxdat_148D_MEAN', 'refreshdate_3813885D_MEAN', 'lastapprcredamount_781A', 'daysoverduetolerancedd_3976961L', 'credlmt_935A_MEAN', 'dtlastpmt_581D_MAX', 'mainoccupationinc_437A_MAX', 'numberofoverdueinstlmaxdat_148D_MAX', 'dateofcredstart_181D_MEAN', 'pmts_dpd_303P_MEAN', 'pmts_overdue_1152A_MEAN', 'overdueamountmax2date_1002D_MAX', 'mainoccupationinc_384A_MEAN', 'lastupdate_388D_MEAN', 'numincomingpmts_3546848L', 'dateofrealrepmt_138D_MEAN', 'dtlastpmt_581D_MEAN', 'totalamount_6A_MEAN', 'lastrejectreasonclient_4145040M', 'empl_employedfrom_271D_MAX', 'approvaldate_319D_MEAN', 'overdueamountmax2_398A_MEAN', 'num_group1_MAX_12', 'annualeffectiverate_63L_MAX', 'totalamount_6A_MAX', 'annuity_853A_VAR', 'maininc_215A', 'maxdpdinstldate_3546855D', 'dateofcredend_353D_MEAN', 'firstdatedue_489D', 'numinstpaidearly_338L', 'overdueamountmax_35A_MEAN', 'maxdpdtolerance_577P_VAR', 'numinstlallpaidearly3d_817L', 'pmts_dpd_303P_VAR', 'overdueamountmax2_14A_VAR', 'secondquarter_766L', 'totalamount_6A_VAR', 'credacc_actualbalance_314A_MAX', 'dateactivated_425D_MEAN', 'dpdmaxdatemonth_89T_MAX', 'overdueamountmax2date_1002D_MEAN', 'maxdebt4_972A', 'maxinstallast24m_3658928A', 'numinstlswithdpd10_728L', 'numinstpaidlate1d_3546852L', 'lastcancelreason_561M', 'maxdpdlast6m_474P', 'lastupdate_1112D_MEAN', 'applicationscnt_867L', 'num_group1_MAX_6', 'cntincpaycont9m_3716944L', 'nominalrate_281L_MAX', 'maxdbddpdtollast6m_4187119P', 'avgmaxdpdlast9m_3716943P', 'totalamount_996A_VAR', 'lastactivateddate_801D', 'numinstpaidearly5d_1087L', 'maxdpdinstlnum_3546846P', 'empl_employedfrom_271D_MEAN', 'datelastunpaid_3546854D', 'credlmt_935A_MAX', 'avginstallast24m_3658937A', 'lastupdate_1112D_MAX', 'downpmt_134A_MEAN', 'dpdmax_139P_VAR', 'weekday', 'numberofinstls_320L_MAX', 'collater_valueofguarantee_1124L_MAX', 'lastst_736L', 'pmts_overdue_1152A_VAR', 'monthlyinstlamount_674A_MEAN', 'lastapprdate_640D', 'numberofoverdueinstlmax_1151L_MAX', 'instlamount_768A_VAR', 'maxdpdlast3m_392P', 'dateofcredstart_181D_MAX', 'collater_valueofguarantee_876L_MAX', 'outstandingamount_362A_MAX', 'overdueamountmaxdatemonth_365T_MAX', 'credacc_credlmt_575A_MEAN', 'fourthquarter_440L', 'num_group2_MAX', 'approvaldate_319D_MAX', 'instlamount_768A_MAX', 'byoccupationinc_3656910L_MAX', 'totaloutstanddebtvalue_39A_MEAN', 'eir_270L', 'interestrate_311L', 'overdueamountmax2_398A_MAX', 'outstandingdebt_522A_VAR', 'debtoutstand_525A_MEAN', 'numberofoutstandinstls_59L_MAX', 'numinstregularpaid_973L', 'dateofcredend_353D_MAX', 'thirdquarter_1082L']","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:49:22.696746Z","iopub.execute_input":"2024-05-17T20:49:22.698124Z","iopub.status.idle":"2024-05-17T20:49:22.724106Z","shell.execute_reply.started":"2024-05-17T20:49:22.698050Z","shell.execute_reply":"2024-05-17T20:49:22.721939Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"del df\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:49:22.726284Z","iopub.execute_input":"2024-05-17T20:49:22.727385Z","iopub.status.idle":"2024-05-17T20:49:22.875808Z","shell.execute_reply.started":"2024-05-17T20:49:22.727338Z","shell.execute_reply":"2024-05-17T20:49:22.874322Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"df_train['score'] = 0.0\ndf_test['score'] = 0.0","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:49:22.877725Z","iopub.execute_input":"2024-05-17T20:49:22.878218Z","iopub.status.idle":"2024-05-17T20:49:22.889249Z","shell.execute_reply.started":"2024-05-17T20:49:22.878173Z","shell.execute_reply":"2024-05-17T20:49:22.888022Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# exploration","metadata":{}},{"cell_type":"code","source":"# placeholder for exploration code \n# im doing it on databricks so its faster","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:49:22.890607Z","iopub.execute_input":"2024-05-17T20:49:22.891505Z","iopub.status.idle":"2024-05-17T20:49:22.898386Z","shell.execute_reply.started":"2024-05-17T20:49:22.891467Z","shell.execute_reply":"2024-05-17T20:49:22.897116Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# modeling","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split, StratifiedGroupKFold, StratifiedKFold\nimport lightgbm as lgb \nfrom hyperopt import fmin, tpe, hp, SparkTrials, STATUS_OK\nfrom hyperopt.pyll import scope\nfrom functools import partial","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:49:22.900083Z","iopub.execute_input":"2024-05-17T20:49:22.900830Z","iopub.status.idle":"2024-05-17T20:49:22.912051Z","shell.execute_reply.started":"2024-05-17T20:49:22.900784Z","shell.execute_reply":"2024-05-17T20:49:22.911130Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def gini_stability(base, w_fallingrate=88.0, w_resstd=-0.5):\n    gini_in_time = base.loc[:, [\"week_num\", \"target\", \"score\"]]\\\n        .sort_values(\"week_num\")\\\n        .groupby(\"week_num\")[[\"target\", \"score\"]]\\\n        .apply(lambda x: 2*roc_auc_score(x[\"target\"], x[\"score\"])-1).tolist()\n    \n    x = np.arange(len(gini_in_time))\n    y = gini_in_time\n    a, b = np.polyfit(x, y, 1)\n    y_hat = a*x + b\n    residuals = y - y_hat\n    res_std = np.std(residuals)\n    avg_gini = np.mean(gini_in_time)\n    return avg_gini + w_fallingrate * min(0, a) + w_resstd * res_std","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:49:22.913620Z","iopub.execute_input":"2024-05-17T20:49:22.914371Z","iopub.status.idle":"2024-05-17T20:49:22.924207Z","shell.execute_reply.started":"2024-05-17T20:49:22.914327Z","shell.execute_reply":"2024-05-17T20:49:22.923340Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## tune - lgbm","metadata":{}},{"cell_type":"code","source":"# def get_lgbm_base_params():\n#     base_params = {\n#         'boosting_type':'gbdt',\n#         'random_state': 117,\n#         'objective': 'binary',\n#         'metric': 'auc',\n#         'extra_trees':True,\n#         'verbose': -1,\n#         'max_bin': 256,\n# #         'device_type': 'gpu', 'gpu_use_dp':True,\n        \n#     }\n#     return base_params","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:49:22.925893Z","iopub.execute_input":"2024-05-17T20:49:22.926684Z","iopub.status.idle":"2024-05-17T20:49:22.939923Z","shell.execute_reply.started":"2024-05-17T20:49:22.926632Z","shell.execute_reply":"2024-05-17T20:49:22.938735Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# # set up search space - turn off for submission\n# lgbm_search_space_setup = {\n#     'feature_fraction': hp.uniform('feature_fraction', 0.5, 1),\n#     'max_depth': scope.int(hp.uniform('max_depth', 3, 25)),\n#     'l1_regularization': hp.loguniform('l1_regularization', np.log(.001), np.log(1000)),\n#     'l2_regularization':hp.loguniform('l2_regularization',np.log(.001), np.log(100)),\n#     'cat_l2': hp.loguniform('cat_l2', np.log(.001), np.log(100)),\n#     'bagging_fraction': hp.uniform('bagging_fraction', 0.5, 1),\n#     'bagging_freq': scope.int(hp.uniform('bagging_freq', 2, 10)),\n#     'learning_rate' : hp.loguniform('learning_rate', np.log(0.001), np.log(.1)),\n#     'n_estimators':scope.int(hp.uniform('n_estimators', 500, 2000)),\n#     'num_leaves': scope.int(hp.uniform('num_leaves', 50, 5000)),\n# }\n# lgbm_search_space = get_lgbm_base_params()\n# for k,v in lgbm_search_space_setup.items():\n#     lgbm_search_space[k] = v","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:49:22.941400Z","iopub.execute_input":"2024-05-17T20:49:22.941979Z","iopub.status.idle":"2024-05-17T20:49:22.953305Z","shell.execute_reply.started":"2024-05-17T20:49:22.941936Z","shell.execute_reply":"2024-05-17T20:49:22.952253Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#### do splits ahead of time to improve trial speed - turn off for submission\nk              = 5\n\n# # split by week num\n# group_splits   = [(train_idx,valid_idx) for train_idx,valid_idx in \n#                       StratifiedGroupKFold(n_splits=k).split(np.arange(n_train),\n#                                                              df_train['target'],\n#                                                              groups = df_train['week_num'])]\n# # split by target\n# strat_splits   = [(train_idx,valid_idx) for train_idx,valid_idx in \n#                       StratifiedKFold(n_splits=k).split(np.arange(n_train),\n#                                                              df_train['target'])]\n\n\n# # single split\n# train_idx, test_idx, _, _ = train_test_split(np.arange(n_train),df_train['target'], test_size=0.1, random_state=117,stratify = df_train['target'])\n# single_splits = [(train_idx, test_idx)]","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:49:22.955185Z","iopub.execute_input":"2024-05-17T20:49:22.955910Z","iopub.status.idle":"2024-05-17T20:49:22.964630Z","shell.execute_reply.started":"2024-05-17T20:49:22.955867Z","shell.execute_reply":"2024-05-17T20:49:22.963629Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# def trial_fn_lgbm_gini_stability(params,splits = None):\n    \n\n#     for train_idx, valid_idx in splits:\n#         model = lgb.LGBMClassifier(**params)  \n#         model.fit(df_train.loc[train_idx,features], df_train.loc[train_idx,'target'],\n#                   eval_set=[(df_train.loc[valid_idx,features], df_train.loc[valid_idx,'target'])],\n#                   eval_metric='auc',\n#                   callbacks=[lgb.early_stopping(50)])\n#         df_train.loc[valid_idx,'score'] = model.predict_proba(df_train.loc[valid_idx,features])\n    \n    \n#     score = gini_stability(df_train)\n        \n#     out = {\"status\": STATUS_OK, \"loss\": -score} # always minimizes\n#     return out","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:49:22.965906Z","iopub.execute_input":"2024-05-17T20:49:22.967073Z","iopub.status.idle":"2024-05-17T20:49:22.983281Z","shell.execute_reply.started":"2024-05-17T20:49:22.967029Z","shell.execute_reply":"2024-05-17T20:49:22.982164Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# def trial_fn_lgbm_auc(params,splits = None):\n    \n#     scores = []\n#     for train_idx, valid_idx in splits:\n#         model = lgb.LGBMClassifier(**params)  \n#         model.fit(df_train.loc[train_idx,features], df_train.loc[train_idx,'target'],\n#                   eval_set=[(df_train.loc[valid_idx,features], df_train.loc[valid_idx,'target'])],\n#                   eval_metric='auc',\n#                   callbacks=[lgb.early_stopping(50)])\n\n#         score = roc_auc_score(df_train.loc[valid_idx,'target'],model.predict_proba(df_train.loc[valid_idx,features]))\n#         scores.append(score)\n    \n#     score = np.mean(scores) - np.std(scores)\n#     out = {\"status\": STATUS_OK, \"loss\": -score} # always minimizes\n#     return out","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:49:22.984768Z","iopub.execute_input":"2024-05-17T20:49:22.985884Z","iopub.status.idle":"2024-05-17T20:49:22.997607Z","shell.execute_reply.started":"2024-05-17T20:49:22.985818Z","shell.execute_reply":"2024-05-17T20:49:22.996318Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# best_params = fmin(fn=partial(trial_fn_lgbm_auc, splits = group_splits),\n#                     space=search_space,\n#                     algo=tpe.suggest,\n#                     max_evals=100,\n#                     timeout=60*60*3 # seconds\n#                   )\n# int_params = ['max_depth','n_estimators','bagging_freq','num_leaves']\n# bestp = get_base_params()\n# for k,v in best_params.items():\n#     if k in int_params:\n#         bestp[k] = int(v)\n#     else:\n#         bestp[k] = v\n# bestp","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:49:22.999246Z","iopub.execute_input":"2024-05-17T20:49:22.999653Z","iopub.status.idle":"2024-05-17T20:49:23.013514Z","shell.execute_reply.started":"2024-05-17T20:49:22.999617Z","shell.execute_reply":"2024-05-17T20:49:23.012292Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# best_params = fmin(fn=partial(trial_fn_lgbm_gini_stability, splits = group_splits),\n#                     space=search_space,\n#                     algo=tpe.suggest,\n#                     max_evals=100,\n#                     timeout=60*60*3 # seconds\n#                   )\n# int_params = ['max_depth','n_estimators','bagging_freq','num_leaves']\n# bestp = get_base_params()\n# for k,v in best_params.items():\n#     if k in int_params:\n#         bestp[k] = int(v)\n#     else:\n#         bestp[k] = v\n# bestp","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:49:23.015275Z","iopub.execute_input":"2024-05-17T20:49:23.015988Z","iopub.status.idle":"2024-05-17T20:49:23.024269Z","shell.execute_reply.started":"2024-05-17T20:49:23.015953Z","shell.execute_reply":"2024-05-17T20:49:23.023106Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"## train - lgbm","metadata":{}},{"cell_type":"code","source":"#### do splits ahead of time to improve trial speed - turn off for submission\nk              = 5\n\n# # split by week num\n# group_splits   = [(train_idx,valid_idx) for train_idx,valid_idx in \n#                       StratifiedGroupKFold(n_splits=k).split(np.arange(n_train),\n#                                                              df_train['target'],\n#                                                              groups = df_train['week_num'])]\n# # split by target\n# strat_splits   = [(train_idx,valid_idx) for train_idx,valid_idx in \n#                       StratifiedKFold(n_splits=k).split(np.arange(n_train),\n#                                                              df_train['target'])]\n\n\n# single split\ntrain_idx, test_idx, _, _ = train_test_split(np.arange(n_train),df_train['target'], test_size=0.1, random_state=117,stratify = df_train['target'])","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:49:23.025902Z","iopub.execute_input":"2024-05-17T20:49:23.026556Z","iopub.status.idle":"2024-05-17T20:49:23.753657Z","shell.execute_reply.started":"2024-05-17T20:49:23.026523Z","shell.execute_reply":"2024-05-17T20:49:23.752270Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"bestp = {\n 'random_state': 117,\n 'objective': 'binary',\n 'metric': 'auc',\n 'extra_trees': True,\n 'verbose': -1,\n 'max_bin': 255,\n 'num_estimators': 10000,\n 'bagging_fraction': 0.8785738092050028,\n 'bagging_freq': 2,\n 'feature_fraction': 0.8461039894582675,\n 'lambda_l1': 0.00016035395823821462,\n 'lambda_l2': 0.00026472977300383716,\n 'learning_rate': 0.07658316454314493,\n 'min_data_in_leaf': 1336,\n 'num_leaves': 3427\n}","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:49:23.755158Z","iopub.execute_input":"2024-05-17T20:49:23.755525Z","iopub.status.idle":"2024-05-17T20:49:23.763182Z","shell.execute_reply.started":"2024-05-17T20:49:23.755494Z","shell.execute_reply":"2024-05-17T20:49:23.761931Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# group stratify ensemble\n# for train_idx, valid_idx in group_splits:\n#     model = lgb.LGBMClassifier(**bestp)  \n#     model.fit(df_train.loc[train_idx,features], df_train.loc[train_idx,'target'],\n#               eval_set=[(df_train.loc[valid_idx,features], df_train.loc[valid_idx,'target'])],\n#               eval_metric='auc',\n#               callbacks=[lgb.early_stopping(50)])\n#     df_test['score'] += model.predict_proba(df_test[features])[:,1] / k","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:49:23.764941Z","iopub.execute_input":"2024-05-17T20:49:23.765654Z","iopub.status.idle":"2024-05-17T20:49:23.774554Z","shell.execute_reply.started":"2024-05-17T20:49:23.765608Z","shell.execute_reply":"2024-05-17T20:49:23.773053Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# y stratify ensemble\n\nmodel = lgb.LGBMClassifier(**bestp)  \nmodel.fit(df_train.loc[train_idx,features], df_train.loc[train_idx,'target'],\n          eval_set=[(df_train.loc[test_idx,features], df_train.loc[test_idx,'target'])],\n          eval_metric='auc',\n          callbacks=[lgb.early_stopping(25)])\n\n    \ndf_test['score'] = model.predict_proba(df_test[features])[:,1]","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:49:23.776173Z","iopub.execute_input":"2024-05-17T20:49:23.776537Z","iopub.status.idle":"2024-05-17T20:53:39.596676Z","shell.execute_reply.started":"2024-05-17T20:49:23.776504Z","shell.execute_reply":"2024-05-17T20:53:39.594729Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Training until validation scores don't improve for 25 rounds\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[28], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# y stratify ensemble\u001b[39;00m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbestp)  \n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m          \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m          \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(df_test[features])[:,\u001b[38;5;241m1\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py:1187\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1185\u001b[0m             valid_sets\u001b[38;5;241m.\u001b[39mappend((valid_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39mtransform(valid_y)))\n\u001b[0;32m-> 1187\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_class_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_class_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py:885\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    882\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    883\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m--> 885\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mbest_iteration\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:276\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    269\u001b[0m     cb(callback\u001b[38;5;241m.\u001b[39mCallbackEnv(model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[1;32m    270\u001b[0m                             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    271\u001b[0m                             iteration\u001b[38;5;241m=\u001b[39mi,\n\u001b[1;32m    272\u001b[0m                             begin_iteration\u001b[38;5;241m=\u001b[39minit_iteration,\n\u001b[1;32m    273\u001b[0m                             end_iteration\u001b[38;5;241m=\u001b[39minit_iteration \u001b[38;5;241m+\u001b[39m num_boost_round,\n\u001b[1;32m    274\u001b[0m                             evaluation_result_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m--> 276\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py:3891\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3889\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   3890\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 3891\u001b[0m _safe_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3892\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[1;32m   3895\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# submission","metadata":{}},{"cell_type":"code","source":"# why are rules not implemented to avoid people having to do this hack?\n# hosts are ok with hacking... so I guess we hack. \n# https://www.kaggle.com/competitions/home-credit-credit-risk-model-stability/discussion/497337\n\n\ncondition = df_test['week_num'] < (df_test['week_num'].max()-df_test['week_num'].min())/2 + df_test['week_num'].min() \n\noffset = 0.4 * df_test.loc[condition, 'score'].mean()\n\ndf_test.loc[condition, 'score'] = (df_test.loc[condition, 'score'] - offset).clip(0)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:53:39.597884Z","iopub.status.idle":"2024-05-17T20:53:39.598329Z","shell.execute_reply.started":"2024-05-17T20:53:39.598125Z","shell.execute_reply":"2024-05-17T20:53:39.598143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test[['case_id','score']].to_csv('submission.csv', index=False)\ndf_test[['case_id','score']].head()","metadata":{"execution":{"iopub.status.busy":"2024-05-17T20:53:39.604768Z","iopub.status.idle":"2024-05-17T20:53:39.605235Z","shell.execute_reply.started":"2024-05-17T20:53:39.605031Z","shell.execute_reply":"2024-05-17T20:53:39.605048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}